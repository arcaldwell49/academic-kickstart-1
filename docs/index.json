[{"authors":["admin"],"categories":null,"content":"Hello and welcome to my personal website. I am a exercise physiologist with a Ph.D. in Health, Sport, and Exercise Science from the University of Arkansas. Currently, I work as an ORISE Postdoctoral Fellow at the United States Army Research Institute of Environmental Medicine (USARIEM) where my current research projects are focused on human performance in extreme environments (heat, cold, and altitude). In addition, I am a applied statistician. He has gained expertise in statistics through a Graduate Certificate in Statistics \u0026amp; Research Methods program at the University of Arkansas, and I am recognized by the American Statistical Association as a Graduate Statistician (GStat).\nMy statistics and coding work can be found on GitHub\nLearn about my academic work on ResearchGate.\n","date":1638316800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1638316800,"objectID":"c6a72605ae78ed9155e0cc8112d190d2","permalink":"https://aaroncaldwell.us/authors/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/","section":"authors","summary":"Hello and welcome to my personal website. I am a exercise physiologist with a Ph.D. in Health, Sport, and Exercise Science from the University of Arkansas. Currently, I work as an ORISE Postdoctoral Fellow at the United States Army Research Institute of Environmental Medicine (USARIEM) where my current research projects are focused on human performance in extreme environments (heat, cold, and altitude). In addition, I am a applied statistician. He has gained expertise in statistics through a Graduate Certificate in Statistics \u0026amp; Research Methods program at the University of Arkansas, and I am recognized by the American Statistical Association as a Graduate Statistician (GStat).","tags":null,"title":"","type":"authors"},{"authors":["admin"],"categories":null,"content":"Hello and welcome to my personal website! I am an exercise physiologist with a Ph.D. in Health, Sport, and Exercise Science from the University of Arkansas. Currently, I work as an ORISE Postdoctoral Fellow at the United States Army Research Institute of Environmental Medicine (USARIEM) where my current research projects are focused on human performance in extreme environments (heat, cold, and altitude). In addition, I am a applied statistician and recognized by the American Statistical Association as a Graduate Statistician (GStat). My statistical computing work includes the Superpower, SimplyAgree, and TOSTER R packages.\nMy statistics and coding work can be found on GitHub\nLearn about my academic work on ResearchGate.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://aaroncaldwell.us/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Hello and welcome to my personal website! I am an exercise physiologist with a Ph.D. in Health, Sport, and Exercise Science from the University of Arkansas. Currently, I work as an ORISE Postdoctoral Fellow at the United States Army Research Institute of Environmental Medicine (USARIEM) where my current research projects are focused on human performance in extreme environments (heat, cold, and altitude). In addition, I am a applied statistician and recognized by the American Statistical Association as a Graduate Statistician (GStat).","tags":null,"title":"","type":"authors"},{"authors":null,"categories":null,"content":"","date":1639958400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1639958400,"objectID":"52aea41c3176441cd8b060993a08a260","permalink":"https://aaroncaldwell.us/project/simplyagree/","publishdate":"2021-12-20T00:00:00Z","relpermalink":"/project/simplyagree/","section":"project","summary":"R package for developed for agreement and reliability analyses","tags":["R","Statistics"],"title":"SimplyAgree R package and jamovi module","type":"project"},{"authors":["Rosie Twomey, Vanessa Yingling, Joe Warne, Christoph Schneider, Christopher McCrum, Whitley Atkins, Jennifer Murphy, Claudia Romero Medina, Sena Harlley, Aaron Caldwell"],"categories":null,"content":"Citeable as:\nTwomey, R., Yingling, V., Warne, J., Schneider, C., McCrum, C., Atkins, W., Murphy, J., Romero Medina, C., Harlley, S., \u0026amp; Caldwell, A. (2021). The Nature of Our Literature: A Registered Report on the Positive Result Rate and Reporting Practices in Kinesiology. Communications in Kinesiology, 1(3). https://doi.org/10.51224/cik.v1i3.43\n","date":1638316800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1638316800,"objectID":"73288518f58e5c9690342ab35069739d","permalink":"https://aaroncaldwell.us/publication/nature_literature/","publishdate":"2021-12-01T00:00:00Z","relpermalink":"/publication/nature_literature/","section":"publication","summary":"Scientists rely upon an accurate scientific literature in order to build and test new theories about the natural world. In the past decade, observational studies of the scientific literature have indicated that numerous questionable research practices and poor reporting practices may be hindering scientific progress. In particular, 3 recent studies have indicated an implausibly high rate of studies with positive (i.e., hypothesis confirming) results. In sports medicine, a field closely related to kinesiology, studies that tested a hypothesis indicated support for their primary hypothesis ~70% of the time. However, a study of journals that cover the entire field of kinesiology has yet to be completed, and the quality of other reporting practices, such as clinical trial registration, has not been evaluated. In this study we retrospectively evaluated 300 original research articles from the flagship journals of North America (Medicine and Science in Sports and Exercise), Europe (European Journal of Sport Science), and Australia (Journal of Science and Medicine in Sport). The hypothesis testing rate (~64%) and positive result rate (~81%) were much lower than what has been reported in other fields (e.g., psychology), and there was only weak evidence for our hypothesis that the positive result rate exceeded 80%. However, the positive result rate is still considered unreasonably high. Additionally, most studies did not report trial registration, and rarely included accessible data indicating rather poor reporting practices. The majority of studies relied upon significance testing (~92%), but it was more concerning that a majority of studies (~82%) without a stated hypothesis still relied upon significance testing. Overall, the positive result rate in kinesiology is unacceptably high, despite being lower than other fields such as psychology, and most published manuscripts demonstrated subpar reporting practices.","tags":null,"title":"The Nature of Our Literature: A Registered Report on the Positive Result Rate and Reporting Practices in Kinesiology","type":"publication"},{"authors":["Samuel N Cheuvront , Aaron R Caldwell, Parker J Cheuvront, Robert W Kenefick, Chris Troyanos"],"categories":null,"content":"Citeable as:\nCheuvront, S. N., Caldwell, A. R., Cheuvront, P. J., Kenefick, R. W., \u0026amp; Troyanos, C. (2021). Earlier Boston Marathon Start Time Mitigates Environmental Heat Stress. Medicine and Science in Sports and Exercise. 53(9):1999-2005. https://doi.org/10.1249/mss.0000000000002659\n","date":1633046400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633046400,"objectID":"746d644630ae527807b7491c6dab7c54","permalink":"https://aaroncaldwell.us/publication/bostontemps/","publishdate":"2021-10-01T00:00:00Z","relpermalink":"/publication/bostontemps/","section":"publication","summary":"Purpose: This study aimed to compare the wet bulb globe temperature (WBGT) index and other environmental parameters between early and late Boston Marathon race start times from 1995 to 2016. Methods: Environmental data from 1995 to 2016 (excluding 1996) were used to compare two identical time frames using the 0900-1300 h start versus the 1100-1500 h start. This included the WBGT, dry bulb (Tdb), black globe (Tbg), wet bulb (Twb), solar radiation, relative humidity, and air water vapor pressure. To make comparisons between start times, the difference in the area under the curve (AUC) for each environmental variable was compared within each year with a Wilcoxon signed rank test with a Holm-Bonferroni correction. Results: AUC exposures for WBGT (P = 0.027), Twb (P = 0.031), Tdb (P = 0.027), Tbg (P = 0.055), and solar radiation (P = 0.004) were reduced with an earlier start, whereas those for relative humidity and air water vapor pressure were not. Overall, an earlier race start time by 2 h (0900 vs 1100 h) reduced the odds of experiencing a higher flag category 1.42 times (Î² = 0.1744, P = 0.032). Conclusions: The 2007 decision to make the Boston Marathon start time earlier by 2 h has reduced by ~1.4 times the odds that runners will be exposed to environmental conditions associated with exertional heat illness.","tags":null,"title":"Earlier Boston Marathon Start Time Mitigates Environmental Heat Stress","type":"publication"},{"authors":["Aaron R Caldwell, Kentaro Oki, Shauna M Ward, Jermaine A Ward, Thomas A Mayer, Mark L Plamper, Michelle A King, Lisa R Leon"],"categories":null,"content":"Citeable as:\nCaldwell, A. R., et al. (2021). Impact of successive exertional heat injuries on thermoregulatory and systemic inflammatory responses in mice. Journal of Applied Physiology, 131(5), 1469-1485. ttps://doi.org/10.1152/japplphysiol.00160.2021\n","date":1627776000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627776000,"objectID":"5f4b06d9890a6ddf9d61046b76b12f1e","permalink":"https://aaroncaldwell.us/publication/doublehit/","publishdate":"2021-08-01T00:00:00Z","relpermalink":"/publication/doublehit/","section":"publication","summary":"The purpose of the study was to determine if repeated exertional heat injuries (EHIs) worsen the inflammatory response. We assessed the impact of a single EHI bout (EHI0) or two separate EHI episodes separated by 1 (EHI1), 3 (EHI3), and 7 (EHI7) days in male C57BL/6J mice (n = 236). To induce EHI, mice underwent a forced running protocol until loss of consciousness or core temperature reached â¥ 42.7Â°C. Blood and tissue samples were obtained 30 min, 3 h, 1 day, or 7 days after the EHI. We observed that mice undergoing repeated EHI (EHI1, EHI3, and EHI7) had longer running distances before collapse (â¼528 m), tolerated higher core temperatures (â¼0.18Â°C higher) before collapse, and had higher minimum core temperature (indicative of injury severity) during recovery relative to EHI0 group (â¼2.18Â°C higher; all P ","tags":null,"title":"Impact of successive exertional heat injuries on thermoregulatory and systemic inflammatory responses in mice","type":"publication"},{"authors":[],"categories":["R","statistics"],"content":" Introduction I was on Twitter the other day and saw that Andrew Althouse had a nice thread on simulating an RCT and I wanted to expand on his suggestions and provide some of my own recommendations. In Andrewâs thread he explicitly used base R and only default stats functions that are native to R. While these are great tools, they are limited and most researchers wanting to simulate a study will find these tools lacking when trying to simulate their own particular study. This is not a criticism of Dr.Â Althouseâs thread, it is a wonderful thread, but I want to so a âtidyâ version of this tutorial.\nIn this blog post I will use simstudy as a way to pseudo-replicate these results. My hope is that this post will help make the process of creating your own simulations a little bit easier. In particular, I will advocate that you create your own functions to simulate your studies. This way you can run multiple variations on your simulation with only a few more lines of code (rather than copy and pasting the whole simulation again and again).\n R Packages For this simulation I will try to restrict my use of packages to as few as possible. To simulate the data again I will need the simstudy package and I will also tidyverse set of packages to make the code âtidyâ. In addition, I will need the\nlibrary(simstudy) library(tidyverse) library(data.table) According to Dr.Â Althouseâs documentation he was trying to simulate the following study:\n This code will mimic a 2-group parallel-arm randomized trial using 1:1 allocation of patients to treatment 1 versus treatment 2 For this example, we will use a binary outcome of âdeathâ Patients receiving treatment 1 will have 40% probability of death Patients receiving treatment 2 will have 30% probability of death Analysis will be performed using a logistic regression model We will run 1000 simulated RCTâs and report the odds ratio, 95% confidence interval, and p-value for each simulated trial The âtrueâ treatment effect for a treatment that reduces probability of outcome from 40% to 30% is about OR = 0.642 The power of a trial with N=1000 patients and exactly 1:1 allocation under these assumptions is about 91-92%   Approach So I imagine some people reading this are already starting to sweat about the task ahead. But trust me, if I can do this so can you! OVerall, this is a fairly straightforward process. The process is only made easier when you use the many tools available in R. Also, I am going to create âfunctionsâ which essentially means if I want to run the same simulation again (but maybe change 1 or 2 parameters) this can be done with only a few lines of code. This is efficient and if you are serious about writing your own simulations I would highly recommend writing your own functions.\nStep 1: Create a Data Generating Function This is part looks more complex than it is. All I am doing is making a function that I will call gen_bidat (short for âgenerate binomial dataâ). One of the things Althouse mentions in his code is that his allocation in the simulation is inappropriate. We can get around that by incorporating the functions from simstudy (which randomly assigns group) and keeps things organized through the %\u0026gt;% function. We also will import the data.table package because the simstudy package generates data as data.table type objects.\n# Define function # Parameters ## N = sample size ## props = proportions in each group (length is equal to number of groups) gen_bidat = function(props,N){ # Create data with N participants and balanced assignment to treatment group df = genData(N) %\u0026gt;% # generate data with N participants trtAssign(n = length(props), balanced = TRUE, grpName = \u0026quot;trt\u0026quot;) # Randomly assign treatment (tr) in a balanced fashion # Get the number of gropus by the number or proportions entered grps = length(props) # generate condition for each group # This creates a conditional output # I.e., the odds of the outcome is determined by treatment group for(i in 1:grps){ # run loop once for each group in the study grp = i-1 # the simulation runs from 1 to the total number of groups # the i-1 starts the loop at zero # We then assign the group (grp) by which number in the loop we are in con_run = paste0(\u0026quot;trt == \u0026quot;, grp) # We then grab the assign the correct proportion to the groups in order # We have to create the object dc first (i == 1) # All iterations of the loop add to dc rather than creating a new dc if (i == 1) { dc = defCondition( condition = con_run, formula = props[i], dist = \u0026quot;binary\u0026quot;, link = \u0026quot;identity\u0026quot; ) } else{ dc = defCondition( dc, condition = con_run, formula = props[i], dist = \u0026quot;binary\u0026quot;, link = \u0026quot;identity\u0026quot; ) } } # Now we generate the outcome based on the group (condition) dat \u0026lt;- addCondition(condDefs = dc, dtOld = df, newvar = \u0026quot;y\u0026quot;) return(dat) } # Test run gen_bidat(c(.2,.35),N=10) ## id y trt ## 1: 1 1 1 ## 2: 2 0 1 ## 3: 3 0 0 ## 4: 4 0 0 ## 5: 5 1 0 ## 6: 6 0 0 ## 7: 7 0 0 ## 8: 8 1 1 ## 9: 9 1 1 ## 10: 10 1 1 In some cases the function above is enough. We may just want to generate a data set reflective of study we have designed. We can then âplayâ with the data set to plan analyses for future study. However, that is not what we are after today and we will move onto the power analysis.\n Step 2: Simulation Now we get fancy and run a simulation. All this means is that we run the simulated data (above) for a number of iterations or repetitions (tyically for thousands of iterations). We can make it a power analysis by counting the number of positive results (e.g., below the significance threshold).\nFor the power analysis I created a pwr_bidat function that performs a power analysis with a certain number of repetitions (reps argument). Notice below that I am using the function I just created (gen_bidat) within the pwr_bidat. That is why the user must supply the same information as the last function (the proportions, props, and the sample size, N). In addition, there are two arguments needed for the power analysis: alpha and conf.level. The alpha argument sets the alpha-level for the analyses (i.e., the significance cutoff). While the conf.level argument sets the confidence level (e.g., 95%) for the confidence intervals for the power analysis. We can calculate confidence intervals for a simulation because we have a number of âsuccessâ over a number of attempts (total number of reps). We can use the prop.test function which provides confidence intervals for proportions. This is helpful when for when we are running a small number of simulations and want an idea of what estimates of power are reasonable.\npwr_bidat = function(props,N, reps=100, alpha=.05, conf.level = .95){ # Create 1 to reps simulated data sets sims = replicate(n = reps, gen_bidat(props, N = N), simplify = FALSE) # Run an equivalent number of analyses sims2 = purrr::map(sims, ~ glm(y ~ trt, data = .x, family = binomial(link = \u0026quot;logit\u0026quot;))) # Get the summary coefficients from our models sims3 = purrr::map(sims2, ~ summary(.x)$coefficients) # Put all the results into a data frame (tibble) sims4 = purrr::map(sims3, ~ tibble::rownames_to_column(as.data.frame(.x), \u0026quot;coef\u0026quot;)) # Combine all the data frames into one simsdf = bind_rows(sims4, .id = \u0026quot;nrep\u0026quot;) # Summarize results by coefficient simspow = simsdf %\u0026gt;% group_by(coef) %\u0026gt;% # Calculate the power (number of results with p-value \u0026lt; alpha) summarize( estimate = mean(Estimate), power = mean(`Pr(\u0026gt;|z|)` \u0026lt; alpha), # Calculate confidence intervals power.lci = prop.test(sum(`Pr(\u0026gt;|z|)` \u0026lt; alpha), reps)$conf.int[1], power.uci = prop.test(sum(`Pr(\u0026gt;|z|)` \u0026lt; alpha), reps)$conf.int[2], .groups = \u0026#39;drop\u0026#39; ) # Return table of results return(simspow) } set.seed(01292020) pwr_res = pwr_bidat(c(.4,.3),N=1000) Now that we have the results we can create a table as output using the kable function.\n# Create pretty table to print results knitr::kable(pwr_res %\u0026gt;% rename(Coefficients = coef, `Average Log Odds` = estimate, Power = power, `Lower C.I.` = power.lci, `Upper C.I.` = power.uci), digits = 2, caption = \u0026quot;Result from Power Simulation\u0026quot;)  Table 1: Result from Power Simulation  Coefficients Average Log Odds Power Lower C.I. Upper C.I.    (Intercept) -0.40 0.99 0.94 1.00  trt -0.47 0.95 0.88 0.98    Based on these results we can can conclude that a study of 1000 patients randomly assigned to one of two treatment groups wherein 30% of participants die in treatment group #1 and 40% perish in treatment group #2 will have approximately 95% power [0.88,0.98]. Notice, that compared to Dr.Â Althouseâs thread, I estimated the power at 95% (thread noted power at ~92.3%). This is to be expected when simulating data and is why a high number of repetitions are needed to determine power.\n Why more complicated code? Well, here is why create functions: it is easier on future me. Say, I run three separate simulations with minor differences so I go about with the Althouse approach (maybe even copy and paste the code a few times). Later, I notice a flaw in my code, or maybe there is a small change that alters all three simulations. Well, if I take the time to create the simulations then all I have to do is change the code in 1 place (where I defined the function) rather than with every chunk of code that includes the simulation code.\nAlso, it is easier to produce variations on the same design. Letâs imagine we are doing a study on a treatment for an infectious disease that has a hospitalization rate of at least 3.5% people that are infected (so treatment occurs immediately upon diagnosis). The study investigators want to know if 2000 patients are enough to detect if the proposed treatment reduces the hospitalization rate at least by half (1.75%).\nAll I have to do is use the same function I have created above but change the arguments in the function.\npwr_2 = pwr_bidat(c(.035,.0175),N=2000) knitr::kable(pwr_2, caption = \u0026quot;Another Study of Binary Outcomes\u0026quot;)  Table 2: Another Study of Binary Outcomes  coef estimate power power.lci power.uci    (Intercept) -3.343981 1.00 0.9538987 1.000000  trt -0.704106 0.69 0.5885509 0.776633    Now, we have the new results in only 4 lines of code! Based on those results we would likely advise the investigators that they will need a larger sample size to conclude effectiveness for their proposed treatment.\n  Conclusions In this blog post, I have demonstrated how to create 2 R functions that 1) generate data and 2) generate a simulation based power analysis. Simulation is not necessary for a simple analysis such as this where analytic solutions exist in programs like GPower. However, as I will detail in future posts, simulation becomes very useful when the design becomes complicated (or when we want to violate the assumptions of the models we use).\nHopefully, this process appears straightforward. If not send me a message and I can try to bridge the gap!\n ","date":1611956358,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611956358,"objectID":"326ececaf0dcacc8d944f6c035a944bd","permalink":"https://aaroncaldwell.us/post/intro-binary-sim/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/intro-binary-sim/","section":"post","summary":"Introduction I was on Twitter the other day and saw that Andrew Althouse had a nice thread on simulating an RCT and I wanted to expand on his suggestions and provide some of my own recommendations. In Andrewâs thread he explicitly used base R and only default stats functions that are native to R. While these are great tools, they are limited and most researchers wanting to simulate a study will find these tools lacking when trying to simulate their own particular study.","tags":["simulation","introduction"],"title":"Simulating a Study with a Binary Outcome","type":"post"},{"authors":[],"categories":["R","statistics"],"content":" Introduction A little over a year ago Patrick Forscher wrote a very nice blog post about a simple way to increase the severity of a hypothesis test in a multi-group experimental design (in this case one factor, 3-group design). He highlights the main problem as the following:\n Multi-group designs are the workhorse of scientific psychology. Multi-group designs apply to any grouping of people, within-person states, situations, or stimuli; interest typically centers around the either the means or conditional means within each group. However, theory-testing using these means typically proceeds in just the way that Meehl criticized: scientists attempt to reject a null hypothesis of no group mean differences (which, due to Meehlâs âcrudâ, may be trivially false a priori), then follow up the rejected null hypothesis with tests intended to diagnose the pattern that produced the rejected null.\n I agree that this is systemic problem. People sometimes default to just plugging numbers into a one-way ANOVA and usually conclude that their hypothesis is confirmed simply by a significant ANOVA-level effect. Patrickâs proposed solution to the problem is a priori orthogonal contrasts. As a quick aside, I am always shocked at how few people know about orthogonal contrasts. This was drilled into my head by my statistics professors at Arkansas (Thank you Ronna Turner and Sean Mulvenon!). For more details on orthogonal contrasts (and experimental design altogether), I highly recommend purchasing a copy of âDesigning Experiments and Analyzing Dataâ by Maxwell, Delaney, and Kelley (2018). It covers this and numerous other topics; you wonât find a better value in a statistics textbook.\n R Code Now I will go through the code in R for how to implement Patrickâs approach using the afex and emmeans package. For more details on why you should use this approach please read Patrickâs blogpost!\nOrthogonal Contrasts There are many helper functions in R that make it easy to use orthogonal contrasts without having to write out the contrasts by hand. I will show these later but I quickly want to show a technique for checking your set of contrasts to ensure they are in fact orthogonal. Essentially, I have a function that takes the contrasts as matrix and calculates the cross-products of the matrix. If any off-diagonal element is not equal to zero then the contrasts are not orthogonal. Please note, that I made this function in ~2 minutes so I havenât quite checked to ensure it works in all situations.\n# build function check_orthog = function(contrast_mat) { check_off = crossprod(contrast_mat) upper_check = sum(check_off*upper.tri(check_off)) lower_check = sum(check_off*lower.tri(check_off)) if (upper_check == 0 \u0026amp;\u0026amp; lower_check == 0) { return(TRUE) } else{ return(FALSE) } } # Test with Patrick\u0026#39;s code -- should print TRUE c1 \u0026lt;- c(-1/2,0,1/2) c2 \u0026lt;- c(1/3,-2/3,1/3) cons = cbind(c1,c2) check_orthog(cons) ## [1] TRUE # Create non-orthogonal contrasts -- should print FALSE cons2 = cbind(c(-1,1,0), c(0,-1,1), c(-1,0,1)) check_orthog(cons2) ## [1] FALSE # Another way of coding orthogonal polynomial contrasts. c1 \u0026lt;- c(-1, 0, 1) c2 \u0026lt;- c(0.5, -1, 0.5) cons3 \u0026lt;- cbind(c1,c2) # Again should print TRUE check_orthog(cons3) ## [1] TRUE I will use this at points in the blogpost just to check my own contrast coding (please email me if you notice a mistake!).\n Generate Data First, I will generate some data. Please note for this portion of the post I will be directly replicating/copying Patrickâs data and code.\nlibrary(tidyverse) library(afex) library(emmeans) library(broom) set.seed(432432) # For reproducibility # For all examples, I\u0026#39;m using the below sampling error sd and n per cell err \u0026lt;- 1 n_per_cell \u0026lt;- 200 # I\u0026#39;m also assuming the following: # (1) our smallest effect of substantive interest is .4 # (2) all contrasts are Helment (successively compare one group to the average of the others) # (3) all contrasts are unit-weighted # This method should generalize to other orthogonal contrasts # The parameter estimates for unit-weighted Helmert contrasts, however, have a # nice interpretation as a series of mean differences and are therefore easy to understand #### THREE GROUP #### # Ceofficients for this case. Modify as desired # First is the intercept, second is the focal contrast, remainder are the residual contrasts coefs \u0026lt;- c(0, .7, .2) # Create the data # The last line creates the outcome using the coefficients above and the desired sampling error, err # %*% is matrix multiplication dat_three \u0026lt;- data.frame(group = rep(paste(\u0026quot;group\u0026quot;, 1:3), n_per_cell)) dat_three \u0026lt;- mutate( dat_three, c1 = case_when(group == \u0026quot;group 1\u0026quot; ~ 2 / 3, TRUE ~ -1 / 3), c2 = case_when(group == \u0026quot;group 1\u0026quot; ~ 0, group == \u0026quot;group 2\u0026quot; ~ 1 / 2, TRUE ~ -1 / 2), outcome = as.vector(cbind(1, c1, c2) %*% coefs + rnorm(nrow(dat_three), sd = err)) ) %\u0026gt;% mutate(group = factor(group, levels = c(\u0026quot;group 1\u0026quot;, \u0026quot;group 2\u0026quot;, \u0026quot;group 3\u0026quot;), ordered = TRUE)) # creates and ordered \u0026amp; labeled factor for group knitr::kable(head(dat_three), caption = \u0026quot;3-group data\u0026quot;)  Table 1: 3-group data  group c1 c2 outcome    group 1 0.6666667 0.0 0.1940993  group 2 -0.3333333 0.5 -0.5684096  group 3 -0.3333333 -0.5 -0.3451584  group 1 0.6666667 0.0 1.4218414  group 2 -0.3333333 0.5 0.2550905  group 3 -0.3333333 -0.5 0.3534099    Now, we have some data to work with. However, rather than simply using the lm function to make the contrast comparisons I will use afex to build the model and then emmeans to apply the specific contrasts.\n Three Group Example In Patrickâs post he used the lm function to test the contrasts. I think this fine but may be difficult to understand for many beginners. Plus any addition comparisons will have to be made by creating a new model. This is why I prefer using afex: it has an easier to use interface and the model can be passed onto emmeans for specific additional comparisons. If Patrickâs approach works for you that is great, but I want to make sure people know of alternative approaches.\n# Patrick\u0026#39;s Example m_three \u0026lt;- lm(outcome ~ c1 + c2, data=dat_three) knitr::kable(tidy(m_three), caption = \u0026quot;3-group Contrasts using lm\u0026quot;)  Table 2: 3-group Contrasts using lm  term estimate std.error statistic p.value    (Intercept) 0.0437823 0.0417829 1.047853 0.2951303  c1 0.6570966 0.0886348 7.413527 0.0000000  c2 0.1873883 0.1023467 1.830918 0.0676111    Now, let us go through the same process with afex and emmeans. We will need to create an id column so that afex knows that these are all between-subject comparisons. I also like to have the partial eta squared (\\(\\eta^2\\)) for the default effect size output so I am also going to set this using the afex_options function.\n# Add subject id dat_three = rowid_to_column(dat_three, var = \u0026quot;id\u0026quot;) afex_options(es_aov = \u0026quot;pes\u0026quot;) # Build model using afex; note we must have an error term \u0026quot;(1|id)\u0026quot; afex_three = afex::aov_4(outcome ~ group + (1|id), data = dat_three) ## Contrasts set to contr.sum for the following variables: group # Output tyical ANOVA table with type-3 SS knitr::kable(nice(afex_three))   Effect df MSE F pes p.value    group 2, 597 1.05 29.16 *** .089 \u0026lt;.001    Most people reading this should be familiar with the table above. It is a simple one-way ANOVA output.\nNow I can make the same comparisons Patrick made with lm using emmeans. However, I can also make my tests directionl using the side argument in the contrast function.\n# Now get emmeans emm_three = emmeans(afex_three, ~group) # Estimated marginal means knitr::kable(tidy(emm_three) %\u0026gt;% select(-df,-statistic,-p.value))   group estimate std.error    group 1 0.4818467 0.07237  group 2 -0.0815557 0.07237  group 3 -0.2689441 0.07237    # Create orthogonal contrasts con_three = list(c1 = c(1,-.5,-.5), c2 = c(0,1,-1)) check_orthog(cbind(con_three$c1, con_three$c2)) ## [1] TRUE # Make comparisons with contrast function knitr::kable(contrast(emm_three,con_three), caption = \u0026quot;3-group emmeans contrasts\u0026quot;)  Table 3: 3-group emmeans contrasts  contrast estimate SE df t.ratio p.value    c1 0.6570966 0.0886348 597 7.413527 0.0000000  c2 0.1873883 0.1023467 597 1.830918 0.0676111    knitr::kable(contrast(emm_three,con_three, side = \u0026quot;\u0026gt;\u0026quot;), caption = \u0026quot;3-group emmeans w/ directional contrasts\u0026quot;)  Table 3: 3-group emmeans w/ directional contrasts  contrast estimate SE df t.ratio p.value    c1 0.6570966 0.0886348 597 7.413527 0.0000000  c2 0.1873883 0.1023467 597 1.830918 0.0338055    Patrick also mentions that we would want to perform equivalence tests to rule out that the differences are within our equivalence bounds (answers the question âAre these contrast differences, if they exist, smaller than what we consider meaningful?â). Remember, c1 is âgroup 1 - group 2 \u0026amp; group 3â and c2 is âgroup 2 - group 3â.\n# Create contrast con_three_eq = contrast(emm_three,con_three) # Perform equivalence test (takes absolute difference) test_three_eq = test(con_three_eq, delta = .4, # eq bound side = \u0026quot;equivalence\u0026quot;) knitr::kable(test_three_eq, caption = \u0026quot;Equivalence Tests for 3-group example\u0026quot;)  Table 4: Equivalence Tests for 3-group example  contrast estimate SE df t.ratio p.value    c1 0.6570966 0.0886348 597 2.900628 0.9980694  c2 0.1873883 0.1023467 597 -2.077368 0.0190973     Four Group Example Again, we will need to generate the same data that Patrick did in his post.\n#### FOUR GROUP #### # Ceofficients for this case. Modify as desired # First is the intercept, second is the focal contrast, remainder are the residual contrasts coefs \u0026lt;- c(0, .7, .2, .1) # Create the data # The last line creates the outcome using the coefficients above and the desired sampling error, err # %*% is matrix multiplication dat_four \u0026lt;- data.frame(group = rep(paste(\u0026quot;group\u0026quot;, 1:4), n_per_cell)) dat_four \u0026lt;- mutate( dat_four, c1 = case_when(group == \u0026quot;group 1\u0026quot; ~ -3 / 4, TRUE ~ 1 / 4), c2 = case_when(group == \u0026quot;group 1\u0026quot; ~ 0, group == \u0026quot;group 2\u0026quot; ~ 2 / 3, TRUE ~ -1 / 3), c3 = case_when( group %in% c(\u0026quot;group 1\u0026quot;, \u0026quot;group 2\u0026quot;) ~ 0, group == \u0026quot;group 3\u0026quot; ~ 1 / 2, TRUE ~ -1 / 2 ), outcome = as.vector(cbind(1, c1, c2, c3) %*% coefs + rnorm(nrow(dat_four), sd = err)) ) %\u0026gt;% mutate(group = factor( group, levels = c(\u0026quot;group 1\u0026quot;, \u0026quot;group 2\u0026quot;, \u0026quot;group 3\u0026quot;, \u0026quot;group 4\u0026quot;), ordered = TRUE )) %\u0026gt;% # creates and ordered \u0026amp; labeled factor for group rowid_to_column(var = \u0026quot;id\u0026quot;) knitr::kable(head(dat_four), caption = \u0026quot;4-Groups Data\u0026quot;)  Table 5: 4-Groups Data  id group c1 c2 c3 outcome    1 group 1 -0.75 0.0000000 0.0 -0.6004404  2 group 2 0.25 0.6666667 0.0 1.4770844  3 group 3 0.25 -0.3333333 0.5 2.2156623  4 group 4 0.25 -0.3333333 -0.5 -0.1881092  5 group 1 -0.75 0.0000000 0.0 0.4617127  6 group 2 0.25 0.6666667 0.0 0.0611009    Now, we replicate the process to build our base model.\n# Build model using afex; note we must have an error term \u0026quot;(1|id)\u0026quot; afex_four = afex::aov_4(outcome ~ group + (1|id), data = dat_four) ## Contrasts set to contr.sum for the following variables: group # Output tyical ANOVA table with type-3 SS knitr::kable(nice(afex_four), caption = \u0026quot;ANOVA: Four Groups\u0026quot;)  Table 6: ANOVA: Four Groups  Effect df MSE F pes p.value    group 3, 796 1.02 25.52 *** .088 \u0026lt;.001    And, we can then pass on this model to the emmeans function to make our specific contrasts.\n# Now get emmeans emm_four = emmeans(afex_four, ~group, adjust = \u0026quot;none\u0026quot;) # Estimated marginal means knitr::kable(tidy(emm_four) %\u0026gt;% select(-df,-statistic,-p.value))   group estimate std.error    group 1 -0.5275826 0.0714616  group 2 0.3089254 0.0714616  group 3 0.1323786 0.0714616  group 4 0.0253503 0.0714616    # Create orthogonal contrasts con_four = list(c1 = c(1,-1/3,-1/3,-1/3), c2 = c(0,1,-0.5,-0.5), c3 = c(0,0,.5,-.5)) check_orthog(cbind(con_four$c1, con_four$c2, con_four$c3)) ## [1] TRUE # Perform joint test knitr::kable(test(contrast(emm_four, con_four[2:3]), joint = TRUE), caption = \u0026quot;Joint Test of Residual Contrasts\u0026quot;)  Table 7: Joint Test of Residual Contrasts  df1 df2 F.ratio p.value    2 796 4.016 0.0183995    We start by performing âjoint testâ of the residual hypotheses (Note: c1 is the focal hypothesis so we only include c2 and c3). Now, we observed that our residual contrasts actually account for a significant portion of the variance.\nSo, we can perform equivalence testing for these contrasts. We find that c2 and c3 are within our equivalence bounds.\n# Make comparisons with contrast function knitr::kable(test(contrast(emm_four, con_four), delta = .4, side = \u0026quot;equivalence\u0026quot;), caption = \u0026quot;4-group equivalence contrasts\u0026quot;)  Table 8: 4-group equivalence contrasts  contrast estimate SE df t.ratio p.value    c1 -0.6831340 0.0825167 796 3.431233 0.9996841  c2 0.2300610 0.0875222 796 -1.941668 0.0262649  c3 0.0535141 0.0505310 796 -6.856903 0.0000000    Then, we can finally test focal hypothesis c1.\nknitr::kable(tidy(contrast(emm_four,con_four[1])), caption = \u0026quot;4-group: c1 contrast\u0026quot;)  Table 9: 4-group: c1 contrast  term contrast null.value estimate std.error df statistic p.value    group c1 0 -0.683134 0.0825167 796 -8.278736 0    From these results Patrick concludes the following (and I agree).\n In this case, although the deviation from the focal contrast is significantly different from zero, we can say that the amount of deviation is smaller than our threshold for what constitutes a meaningful effect. If we think that any deviation from the focal contrast is reason for concern, we might think about amending our theory. If, on the other hand, we believe that the null hypothesis of no relationship is basically always false and that many of these non-zero relationships are âcrudâ, we might advance the claim that our theory has been corroborated. In either case our testing procedure is more severe than a mere test of the null hypothesis of no differences between group means.\n Another way of saying this is the following: despite the data being incompatibility with the focal contrast (evidenced by the joint test), the differences observed in these other contrasts is small or within the established equivalence bounds. Meanwhile, we can reject the null hypothesis that our focal contrast is zero.\n  Extension to Multilevel/Hierarchical Models In many cases, the designs that Patrick laid out are as simple or clean as a 3-group one-way ANOVA. Very often we have multiple levels of variance we would like to take into account. The most common example, and one I will repeat here, is in education wherein we have students inside classes within schools. In addition, we often have covariates that (like gender, socioecononimc status, or age) and we need to include those in our models.\nSo, I will apply Patrickâs approach to a study where we have test scores on students within classes within schools. We also have informative covariates such as age and gender on the test scores. Let us say we are testing the hypothesis that our intended treatments (groups 2 and 3) will have a positive effect, and there will be an additional benefit for treatment group 3. Therefore, we will have similar contrasts to the original 3-group example except we will reverse the coding and only have one-sided tests because I specified directional hypotheses.\nlibrary(simstudy) # taken from https://kgoldfeld.github.io/simstudy/articles/clustered.html gen.school \u0026lt;- defData( varname = \u0026quot;s0\u0026quot;, dist = \u0026quot;normal\u0026quot;, formula = 0, variance = 3, id = \u0026quot;idSchool\u0026quot; ) gen.school \u0026lt;- defData(gen.school, varname = \u0026quot;nClasses\u0026quot;, dist = \u0026quot;noZeroPoisson\u0026quot;, formula = 3) set.seed(282721) dtSchool \u0026lt;- genData(8, gen.school) dtSchool \u0026lt;- trtAssign(dtSchool, nTrt = 3) gen.class \u0026lt;- defDataAdd( varname = \u0026quot;c0\u0026quot;, dist = \u0026quot;normal\u0026quot;, formula = 0, variance = 2 ) gen.class \u0026lt;- defDataAdd(gen.class, varname = \u0026quot;nStudents\u0026quot;, dist = \u0026quot;noZeroPoisson\u0026quot;, formula = 20) dtClass \u0026lt;- genCluster(dtSchool, \u0026quot;idSchool\u0026quot;, numIndsVar = \u0026quot;nClasses\u0026quot;, level1ID = \u0026quot;idClass\u0026quot;) dtClass \u0026lt;- addColumns(gen.class, dtClass) %\u0026gt;% mutate(t2 = ifelse(trtGrp == 2, 1, 0), t3 = ifelse(trtGrp == 3, 1, 0)) gen.student \u0026lt;- defDataAdd(varname = \u0026quot;Male\u0026quot;, dist = \u0026quot;binary\u0026quot;, formula = 0.5) gen.student \u0026lt;- defDataAdd(gen.student, varname = \u0026quot;age\u0026quot;, dist = \u0026quot;uniform\u0026quot;, formula = \u0026quot;9.5; 10.5\u0026quot;) gen.student \u0026lt;- defDataAdd( gen.student, varname = \u0026quot;test\u0026quot;, dist = \u0026quot;normal\u0026quot;, formula = \u0026quot;50 - 2*Male + s0 + c0 + 4 * t2 + 12 * t3\u0026quot;, variance = 2 ) dtStudent \u0026lt;- genCluster( dtClass, cLevelVar = \u0026quot;idClass\u0026quot;, numIndsVar = \u0026quot;nStudents\u0026quot;, level1ID = \u0026quot;idChild\u0026quot; ) con_three = list(c1 = c(-1,.5,.5), c2 = c(0,1,-1)) check_orthog(cbind(con_three$c1, con_three$c2)) ## [1] TRUE dat_mlm \u0026lt;- addColumns(gen.student, dtStudent) %\u0026gt;% select(-s0,-c0,-t2,-t3) %\u0026gt;% mutate(trtGrp = factor(trtGrp, levels = c(1,2,3), ordered = TRUE)) Now we can utilize the lme4 package to build the mlm and use emmeans plot function to take a glimpse at the difference between groups.\ntest_mlm = lme4::lmer(test ~ Male + trtGrp + (1|idClass:idSchool) + (1|idSchool), data = dat_mlm) knitr::kable(broom.mixed::tidy(test_mlm), caption = \u0026quot;Summary Table of MLM\u0026quot;) ## Registered S3 method overwritten by \u0026#39;broom.mixed\u0026#39;: ## method from ## tidy.gamlss broom  Table 10: Summary Table of MLM  effect group term estimate std.error statistic    fixed NA (Intercept) 55.9993351 0.5561662 100.688138  fixed NA Male -1.7990154 0.1491026 -12.065621  fixed NA trtGrp.L 7.6402443 0.7468733 10.229640  fixed NA trtGrp.Q 2.0859008 1.1211914 1.860432  ran_pars idClass:idSchool sd__(Intercept) 1.4617520 NA NA  ran_pars idSchool sd__(Intercept) 0.9791225 NA NA  ran_pars Residual sd__Observation 1.5290580 NA NA    # Plot estimated differences between treatments emm_mlm = emmeans(test_mlm, ~ trtGrp) plot(emm_mlm) Finally, we can apply emmeans to look at the our specific contrasts. For these multi-level models emmeans defaults to Kenword-Roger degrees of freedom.\ncon_mlm = list(c1 = c(-1,.5,.5), c2 = c(0,-1,1)) check_orthog(cbind(con_mlm$c1, con_mlm$c2)) ## [1] TRUE knitr::kable(test(contrast(emm_mlm, con_mlm), side = \u0026quot;\u0026gt;\u0026quot;))   contrast estimate SE df t.ratio p.value    c1 6.826355 1.030733 5.934995 6.622817 0.0002986  c2 7.957165 1.489940 10.030437 5.340594 0.0001623    We see that our data is incompatible with the null hypotheses. We may also want to include âconditional equivalence testsâ to ensure that our effects are not within a range we deem practically equivalent. Therefore, we can use almost the same code as the chunk above but add a delta argument as well as change the side argument to âequivalentâ.\nknitr::kable(test(contrast(emm_mlm, con_mlm), delta = 2, side = \u0026quot;equivalent\u0026quot;))   contrast estimate SE df t.ratio p.value    c1 6.826355 1.030733 5.934995 4.682450 0.9982574  c2 7.957165 1.489940 10.030437 3.998258 0.9987449     Conclusion As you can see the process of creating specific contrasts is fairly straightforward in R and the hypothesis testing procedures are simplified by using the emmeans package. I find contrast coding to be a refreshing alternative to the typical inspection of âANOVA-levelâ effects that is often followed up pairwise comparisions between the levels of a factor where there is a significant effect. Instead, contrast coding demands that the user be specific in their hypotheses. As Patrick notes in his blog post, specifying these contrasts a priori in many cases may result in a more severe tests of your hypotheses which arguably increases the strength of your claims if your experiments support your hypotheses. In my opinion there is added advantage in how you can go about describign your results (no need for the mundane langauge about âsignificant main effectsâ). Also, orthogonal contrasts, by nature, do not require adjustments for multiplicity and therefore may be more statistical powerful than default ANOVA tests. Iâll admit that orthogonal contrasts are not a silver bullet (there is no free lunch in statistics), but I do believe there many experiments that would benefit from this type of analysis.\nMiscellaneous Notes There are other ways to code contrasts. This post by Rose Maier notes a way of performing contrasts with the summary function. https://rstudio-pubs-static.s3.amazonaws.com/65059_586f394d8eb84f84b1baaf56ffb6b47f.html\n  ","date":1605876007,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605876007,"objectID":"7c569f5801e0b5322efea88de7bffa8d","permalink":"https://aaroncaldwell.us/post/severity-multigroup/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/severity-multigroup/","section":"post","summary":"Introduction A little over a year ago Patrick Forscher wrote a very nice blog post about a simple way to increase the severity of a hypothesis test in a multi-group experimental design (in this case one factor, 3-group design). He highlights the main problem as the following:\n Multi-group designs are the workhorse of scientific psychology. Multi-group designs apply to any grouping of people, within-person states, situations, or stimuli; interest typically centers around the either the means or conditional means within each group.","tags":["R","statistics","hypothesis testing","polynomial","contrasts","emmeans"],"title":"Increasing testing severity in multi-group designs","type":"post"},{"authors":null,"categories":"statistics","content":" Updated on: 2020-08-25\n I equate trying to change the reporting practices of statistics with trying to change the direction of an ocean liner with a kayak. Good luck with that. When I mentioned this analogy to a colleague, he said, âWhat we need are more kayaks. A lot more kayaks.â I understand it is difficult to change entrenched practices. I get that change is slow. But that does not mean we should not try. â Douglas Curran-Everett (2020)\n Last week, a manuscript I co-authored was finally published by the British Journal of Sports Medicine. The point of this opinion piece was to encourage more exercise \u0026amp; sport scientists engage with the statistics literature and, when necessary, seek out collaborators with statistical expertise. As part of our âCall to Actionâ we highlighted our fields problems with statistics which include mistakes made in published literature and our fields proclivity towards creating novel statistical methods. I hope this manuscript is a rallying call to everyone in the field with in an interest in statistics. In this blog post, I want to take a critical view of our manuscript, and provide further insight into my perspective.\nSome Background I think it may help the reader understand the perspectives contained within the paper if they understood more about how and why this paper was written. First, the lead author, Kristin Sainani, organized the writing effort and invited authors to join the paper based on mutual frustrations with the current state of sport and exercise science. This is a fairly diverse group that includes senior academics, actual statisticians, people working in industry/government, and even a PhD student. As one might expect, we all have different perspectives, and often disagree on what constitutes appropriate statistical practice. In fact, this paper took quite some time to finish because of disagreements among the authors on what policies we should recommend, what things we should criticize, and even the tone of our message. It would be a mistake to assume we are acting as monolithic group vying for control of the scientific literature. I actually wouldnât be surprised if at some point in the near future there are public criticisms of each others work! Regardless, we eventually did come to a consensus and we all agreed to the final version that was published this past week. Kristin did a wonderful job organizing this effort (which was probably akin to herding cats), and I am proud to be included as a co-author.\nFrom here, Iâll start with some limitations of our article, and then talk about the larger themes.\n Limitations worth discussion Our analysis In the paper, we state only 13.3% of articles we surveyed (k = 299) employed some type of statistical methods expert. From this information, we state there is a shortage of âstatisticiansâ to collaborate on these studies and imply that increasing that proportion would be beneficial to sport and exercise science. However, there are limits to what we can actually say with this data. All the data can really tell us is that the majority of sport and exercise scientists do not collaborate with statisticians in a way that merits authorship. This excludes situations where statisticians were consulted but not included on the manuscript, and excludes those with formal statistics training embedded with departments that do sport and exercise science research (more on that below). As we stated in the supplement this analysis is also limited by the criteria we used to count statistical collaborators. On a personal note, many of my own papers would not meet the criteria we outlined. Now, I do not consider myself a statistician (yet), but a lot of my papers in graduate school did include a statistician (Big thanks to Ronna Turner and Sean Mulvenon). However, in most cases we simply listed our college (College of Education and Health Sciences) of which the Department Educational Statistics and Research Methods was located within. Nonetheless, Kristin Sainani and David Borg checked a subset of 30 articles and found only 1 case where a staff statistician, who was embedded within a non-stats department, was included on a manuscript.\nMoreover, I think most of (if not all) my co-authors would agree that some quantitative studies do not require much statistical expertise in order to be analyzed properly. I am reminded of the time a colleague, who is well trained in statistics, told me âI donât think there is a single research question or experimental design I am interested in that would require more than a t-testâ. While I think such a situation is rare, it does illustrate an important point: sometimes a statistician is not necessary. I am reminded of some of the basic (i.e.Â animal/cell model) physiologists I have worked with in the past where their experiments are so precise and well-controlled that statistics are rarely necessary. I like to call these âlight switch studiesâ because if the effect the physiologists were studying is real it would be as clear as turning on a light switch in a windowless room. The problem is more of knowing when to consult a statistician rather than always having a statistician review your work. It is difficult to have the humility to admit when you require an additional assistance. Those with some statistical training, I include myself in this group, should be wary of the âBeginners Bubble Effectâ, or the tendency to be overconfident in our knowledge/abilities once we have gained only a beginners-level knowledge (Sanchez and Dunning 2018). According to David Dunning, this is different than the well-known Kruger-Dunning Effect.\nOverall, our data cannot prove that sport scientists lack statistics training or that all researchers absolutely need to have a statistician on their papers/projects for their results to be valid. Instead, my takeaway is that statistical collaboration is exceedingly rare, and since many sport scientists likely havenât collaborated with a statistician, it may be something that many sport scientists should give a try. Honestly, if we could double that percentage (get over 25%) in the next 10 years I would be ecstatic.\n Statistics is not a necessary condition for good science inquiry On Twitter, Jamie Burr brought up a good point that, âstatistics are but one tool to help derive confidence in the conclusions to experimentsâ. For the most part, I agree with this sentiment. I think one omission in our manuscript is that we do not differentiate between quantitative and qualitative research. I think, and I believe most co-authors would agree, that many scientists do not need statistics in order to make scientific discoveries or make scientific advances. There is great value in qualitative, descriptive, or any other variety of work that does not rely upon statistical inference. I want to be clear here and state that such research does not deserve less respect than research that is quantitative in nature. In fact, I believe that many exercise and sport scientist may be better off if they ignored statistics, or at least inferential statistics, and simply spent more time describing the phenomena they are studying. Some have even argued that many scientists may be better off sticking to descriptive statistics (Amrhein, Trafimow, and Greenland 2019) to avoid the pitfalls of statistical inference.\n  My other thoughts More kayaks I started this blog post with a quote from one my role models, Douglas Curran-Everett. He, like myself, has PhD in Physiology but later shifted his focus to statistics (he is an accredited statistician, PStat, of the American Statistical Association). He has been instrumental in my education on statistics and his series in Advances in Physiology Education called âExplorations in Statisticsâ were very helpful in my early understanding of statistics. If you are interested in statistics, I highly suggest you read this series. Dr.Â Curran-Everett exemplifies what I think we need more of in our field: people who are well-trained in the subject matter and statistics. I believe that, in addition to increased statistical collaboration, we need more âstats mavensâ getting in their metaphorical kayaks and pulling us in the right direction.\nSometimes there is going to be disagreement among these stats mavens. Some of my closest collaborators, Andrew Vigotsky and Matt Tenan, disagree on many statistics related topics. That is fine and our debates and discussion have been extremely useful in my own education. The point is we expect a high level of discourse on this subject matter, and expect each other to be able to justify our opinions through simulations and formal mathematics. The latter portion (simulations and math) is what I believe is missing from the current conversation. If we are to have discussions about statistics in the sport and exercise science literature it must be done on the merits of the proposed statistical techniques, and we should expect those outlining an opinion to come with verifiable evidence (e.g., simulations). If we can have this level of discourse I have no doubt our statistical methods will improve over time.\n When to ask for help I think a good question people reading the article may have is âWhen should I ask for statistical expertise?â The answer to that question is complex and varies based on the type of scientific work you do, the complexity of your analyses, and your own level of statistical education. As I mentioned above, many scientists do work that either doesnât require statistics or doesnât require very complex statistics. However, statisticians may provide insights into how to design your experiments and analyze your data that make your studies more efficient and informative. Many of you reading this probably have some training in statistics and know how to perform simple analyses (t-test, ANOVAs, some multiple regression). For this group of people, I think it is important to know the limitations for the techniques you traditionally use, and consult statisticians when you need analyses outside your comfort zone. I sometimes worry that scientists design their studies/questions to fit the statistics (I know I felt that pressure in graduate school). If you have that feeling, or feel like your statistics are not helping answer the question of interest, then it is time to consult with a statistician.\nSome of you reading this may have an extensive background in statistics, and are wondering if I would suggest that even you should consult a statistician. My answer is probably yes, and let me tell you why. I have a âgraduate certificateâ in statistics which involved a minimum of 18 credit hours, but I even took it a step further and took enough classes to qualify for a Masters (though I never formally did a thesis; câest la vie). Despite this training, I still collaborate with other statistics experts on nearly all of my work. For example, I am about to start a large project that involves 2 other statistics/mathematics experts. I need their help because statistics has niches of expertise just like any other field. All of my âstatistics workâ so far is focused on experimental design, standardized effect sizes, and simulating multivariate normal data. When I have work outside my area of expertise then I will consult others that are in that area.\nTL;DR = If you have the opportunity to consult, or develop a working relationship, with a statistician (even if you are statistician yourself) I would take that opportunity.\n We arenât alone As we mention in the opening paragraph of the manuscript, other fields have similar issues with poor statistical practice. A very good example is psychology, and more specifically social psychology (although I am told other sub-fields have similar issues). I would like to highlight the peculiar case of the p-rep (probability of replication) that would have been in our âInventing New Statisticsâ section if it had occurred in sport and exercise science. Overall, the p-rep was simply a transformation of the p-value obtained from a frequentist statistical test. Like other ânovelâ statistical techniques that are not evaluated by traditional statistics standards, the p-rep led to an inappropriate interpretation of probabilities and led people to believe their results were more reliable than they were in actuality. Unfortunately, p-rep was given some praise from those in the psych community, and the Association for Psychological Science (a flagship organization in psychology) actually encouraged authors submitting to their journals to report p-rep over p-values. Not only did this lead to the misinterpretations of results, it has made the work of those doing error detection more difficult or even impossible (This is according to James Heathers on the Everything Hertz podcast). This is was criticized (see Iverson, Lee, and Wagenmakers (2009) for details) and the Association for Psychological Science soon abandoned their policy on p-rep. To my knowledge, the p-rep is no longer being used in any mainstream psychology journals.\nIn the past decade psychology has taken many steps to improve their practices. This field is also helped by the fact that psychology has sub-disciplines that exclusively focus on quantitative methods (e.g., mathematical psychology and psychometrics). There are journals now, like Meta-Psychology, that just focus on the âScience of Scienceâ in an effort to improve research practices. The fruits of this labor are clear: a robust literature on applied statistical methods for psychologists (see the recent work of Daniel Lakens, Eric Wagenmakers, or Lisa DeBruine just to name a few). Please notice that all three examples here are of quantitatively trained psychologist who translate the statistical literature for a psychology audience. They are not introducing anything new or novel other than the vignettes they use as examples or the software theyâve created to help analyze the data. While this field is far from perfect, (e.g., see criticisms of the p-curve) I think there are many actions the field of psychology has taken that our field should emulate.\n Collaborate with everyone Another point I want to emphasize is that I advocate for more than just statistical collaboration. I think we should be collaborating with other subject area experts. For example, my spouse, who is a muscle physiology expert, is currently working with a clinical psychologist on a very interesting project. My spouse brings her physiology expertise to the project and her collaborator brings their extensive clinical experience. Together I think they are going to do some very impactful work because their combined knowledge brings a new perspective to the scientific literature. So, my passion for collaboration isnât limited to statistics. I advocate for collaboration in anything that involves expertise. I think sport and exercise science would benefit from collaborating with more clinicians, psychologists, engineers, or maybe even philosophers.\n  Conclusion If I were to boil our manuscript down into a pithy statement it would be this:\n As sport and exercise scientists we should have the humility to recognize our own limitations, realize as a field we have made a lot of statistical mistakes, and not be afraid to lean on statisticians for help when needed.\n I explicitly want to state that I do not want some version of âstatistics policeâ telling us what we can and cannot publish. Instead, I think my goal can be summed up by the late Doug Altman âWe need less research, better research, and research done for the right reasonsâ, and, in order to accomplish the middle goal, at least some of us have to spend more time and attention on how we use statistics.\nLastly, I want to close on some encouraging words. I believe in the power of our field to advance scientific knowledge and improve our understanding of human performance. Despite our collective mistakes, I believe sport and exercise science has made a positive impact and will continue to do so. We should not âthrow outâ the old, established literature due to statistical mistakes, but look to the old literature to see how we can make improvements. Also, I believe many of those who do not understand statistics, with the appropriate training, can develop some statistical expertise. It was only 7 years ago that I was introduced to the basic concepts of statistics, and I too found myself frustrated by this material (and many of the statisticians who taught it!) Now I find myself empowered by what I have learned, and I am writing tutorial articles to help my peers better understand statistics. Yet, I do not possess any natural skill in mathematics or statistics, despite my love of it. In fact, I was told to give up on learning math during pre-calc by my high school teacher because I, âjust really struggle with this materialâ. I believe there are many more people who, like myself, can enjoy learning and utilizing quantitative methods. Therefore, I encourage my peers to learn more about statistics, read the statistics literature, and engage in conversations about best statistical practice within our field. In order to accomplish the stated goals of our manuscript, we need more, not less, analysts/statisticians coming from our field (and vice versa).\nSo, join us in our kayaks and maybe we can pull this ocean liner in the right direction.\n References Amrhein, Valentin, David Trafimow, and Sander Greenland. 2019. âInferential Statistics as Descriptive Statistics: There Is No Replication Crisis If We Donât Expect Replication.â The American Statistician 73 (sup1): 262â70. https://doi.org/10.1080/00031305.2018.1543137.\n Curran-Everett, Douglas. 2020. âEvolution in Statistics: P Values, Statistical Significance, Kayaks, and Walking Trees.â Advances in Physiology Education 44 (2): 221â24. https://doi.org/10.1152/advan.00054.2020.\n Iverson, Geoffrey J., Michael D. Lee, and Eric-Jan Wagenmakers. 2009. âP Rep Misestimates the Probability of Replication.â Psychonomic Bulletin \u0026amp; Review 16 (2): 424â29. https://doi.org/10.3758/pbr.16.2.424.\n Sanchez, Carmen, and David Dunning. 2018. âOverconfidence Among Beginners: Is a Little Learning a Dangerous Thing?â Journal of Personality and Social Psychology 114 (1): 10â28. https://doi.org/10.1037/pspa0000102.\n   ","date":1598140800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598193100,"objectID":"ffd9c87e2f340fb8ed7c22a47666538d","permalink":"https://aaroncaldwell.us/post/stats-collab/","publishdate":"2020-08-23T00:00:00Z","relpermalink":"/post/stats-collab/","section":"post","summary":"Updated on: 2020-08-25\n I equate trying to change the reporting practices of statistics with trying to change the direction of an ocean liner with a kayak. Good luck with that. When I mentioned this analogy to a colleague, he said, âWhat we need are more kayaks. A lot more kayaks.â I understand it is difficult to change entrenched practices. I get that change is slow. But that does not mean we should not try.","tags":["opinion","comment"],"title":"Clarifying the Meaning of Statistical Collaboration","type":"post"},{"authors":[],"categories":["R","statistics","SAS"],"content":" Updated on: 2020-05-05\nIntroduction There have been a number of criticisms of âmagnitude-based inferencesâ (Batterham and Hopkins 2006) which is a unique approach to statistics in the sport and exercise science community. As an author of the mbir package (Peterson and Caldwell 2019), I have been watching this all develop closely. What is clear from the criticisms is that MBI has some fatal flaws directly related to the sample size estimations and the interpretations of the probabilities that the MBI spreadsheets provide (Lohse et al. 2020; Sainani et al. 2019; Sainani 2018). One of my motivations for helping make mbir was to ensure there was version control of this technique, and that any changes to MBI would be well-documented. Now is the time for changes, and in this short post I will document how apply MBI in a frequentist hypothesis testing framework. The statistical reasoning behind this approach has been outlined in detail by Aisbett, Lakens, and Sainani (2020). I was lucky enough to provide feedback on an earlier version of this manuscript and it inspired me to write this blog post. Changes to mbir will hopefully come soon once Kyle and I agree upon the appropriate path forward for the package (we may add Bayesian options as well). In this document, I will detail how to implement the approach of Aisbett, Lakens, and Sainani (2020) in R and SAS. My hope is that with these details sport and exercise scientists can do three things: 1) go beyond relying entirely on âsignificanceâ, 2) avoid the pitfalls of the âoldâ MBI, and 3) apply analyses that have been well-documented in the statistics literature.\nNote of caution This blog post implicitly assumes researchers are interested in testing hypotheses. This is often not the case for many sport scientists. Researchers may simply want to estimate the magnitude an effect, or may be using inferential statistics as descriptions of the data (Chow and Greenland 2019; Greenland and Chow 2019; Amrhein, Trafimow, and Greenland 2019). Personally, I have no problem with these approaches and would highly recommend the concurve R package as a visualization tool if that is your intention (Rafi and Vigotsky 2020).\n  The Basic Concepts For those of you that have not read Aisbett, Lakens, and Sainani (2020), I will quickly detail what their approach entails. The primary point of their paper is that MBI can be described as combination of two one-sided tests (TOST) for equivalence testing and minimal effects tests (MET). The difference between this approach and the old MBI approach is that now researchers will have to establish an a priori alpha-level, a smallest effect size of interest (SESOI), and justify their sample size on the basis of statistical power. In this format, we must explicitly test hypotheses and remove references to effects being âlikely or very likelyâ or âunclearâ, but rather state whether the data is âcompatible, inconclusive, or ambiguousâ depending on the result (See Table 6 of Aisbett, Lakens, \u0026amp; Sainani 2020). There are other more specific recommendations (such as the removal of the odds ratio calculations), and I highly recommend everyone read Aisbett, Lakens, and Sainani (2020) for more details.\nTerminology Equivalence Testing is a procedure designed to test whether an effect is contained within an equivalence bound. Many people may be familiar with equivalence testing from using TOST (D. Lakens, Scheel, and Isager 2018a). This establishes a null hypothesis that the effect is greater, or less, than the equivalence bound, and the alternative would be that the effect is within the equivalence bound.\nMinimal Effects Testing (MET) is a test to determine whether an effect is large enough to be considered meaningful. In contrast to equivalence testing, a null hypothesis in MET is that the effect is less than an minimal effects bound and the alternative would be that the effect is greater than the bound.\nNon-Inferiority Testing is a test of whether is not worse than a inferiority margin. For example, this is commonly used in bio-pharmaceutical trials where a new, typically cheaper, drug is being introduced and the study is completed simply to show it does not perform worse than the existing option(s).\nTo visualize what these new terms mean, take a look at Figure 1 adapted from D. Lakens, Scheel, and Isager (2018b). A Bayesian interpreation of this can also be found in a recent manuscript from Ravenzwaaij et al. (2019). In essence, we have 2 sets of tests that MBI is using âunder-the-hoodâ when calculating the percentages for each effect. For mechanistic MBI, the âdecisionsâ are made using a combination of TOST \u0026amp; MET. For clinical MBI, the âdecisionsâ are made with a combination of MET and a non-inferiority test with, most likely, differing alphas. Now, under the new approach, you are explicitly stated your hypotheses and testing them with one or combination of the tests listed above. If you read the manuscript by Aisbett, Lakens, and Sainani (2020) you will see this approach is logical and fairly straight forward. But, I imagine many former MBI are unsure how to accomplish this analysis since (1) this usually is not included in typical statistics education and (2) most have relied upon Hopkinsâ spreadsheets to automatically perform the necessary calculations. I understand that many sport and exercise scientists do not have the requisite programming experience in SAS and R to feel comfortable with completing these analyses. In my opinion, it is worth the time to learn at least one of these programming languages, but if demand is great enough I will make a spreadsheet and post it to a repository that facilitates version control (e.g., GitHub).\nFigure 1. Comparison of hypothesis tests. The traditional nil-hypothesis tests (a) the null hypothesis that the effect is exactly equal to zero. The minimal effects test (b) tests against a null hypothesis of the true effect falling between the upper and lower equivalence bound, and the equivalence test (c) tests against the null hypothesis that the true effect is outside (greater or less than) the equivalence bound. Finally, the non-inferiority test (d) tests against the null hypothesis that the effect is at least as great as the bound (in one direction).\n   Application in R First, you will need to have the appropriate R packages for these analyses. I prefer to use afex (Singmann et al. 2020) and emmeans (Lenth 2020) because I find both pacakges easy to use, but other packages or base R functions could be used for these analyses. If you Google âHow do I, insert procedure here, in Râ you will likely get a variety of helpful results. So, if the procedures below donât fit you needs then Iâm sure there are numerous other resources within R that will be helpful. I highly suggest searching stackoverflow for potential solutions. We will also use the tidyverse package (Wickham et al. 2019) to help manage the data and broom to produce some nice looking tables (Robinson and Hayes 2020).\n#Load the emmeans and afex packages library(afex) library(emmeans) library(tidyverse) library(broom) Data Now we need some data to analyze. In R this is straight forward since there are preloaded datasets available. For SAS, I will simply export this data as a csv file then import it into SAS using PROC IMPORT.\n#Simple Three-Group data(\u0026quot;PlantGrowth\u0026quot;) #Factorial data(\u0026quot;ToothGrowth\u0026quot;)  PlantGrowth Dataset  Figure 1: PlantGrowth Data Visualization.  Description:\n âResults from an experiment to compare yields (as measured by dried weight of plants) obtained under a control and two different treatment conditions.â\n head(PlantGrowth) ## weight group ## 1 4.17 ctrl ## 2 5.58 ctrl ## 3 5.18 ctrl ## 4 6.11 ctrl ## 5 4.50 ctrl ## 6 4.61 ctrl  ToothGrowth Dataset  Figure 2: ToothGrowth Data Visualization.  Description:\n âThe response is the length of odontoblasts (cells responsible for tooth growth) in 60 guinea pigs. Each animal received one of three dose levels of vitamin C (0.5, 1, and 2 mg/day) by one of two delivery methods, orange juice or ascorbic acid (a form of vitamin C and coded as VC).â\n head(ToothGrowth) ## len supp dose ## 1 4.2 VC 0.5 ## 2 11.5 VC 0.5 ## 3 7.3 VC 0.5 ## 4 5.8 VC 0.5 ## 5 6.4 VC 0.5 ## 6 10.0 VC 0.5  Analysis of PlantGrowth We will first have to add an âidâ column to the PlantGrowth dataset and then build the ANOVA model using afex. In this scenario, we will consider a difference of 1 unit of weight to be the SESOI.\nPlantGrowth = PlantGrowth %\u0026gt;% dplyr::mutate(id = rownames(PlantGrowth)) mod_plantgrowth = afex::aov_car(weight ~ group + Error(id), data = PlantGrowth) ## Contrasts set to contr.sum for the following variables: group tidyaov_plantgrowth = broom::tidy(mod_plantgrowth$aov) knitr::kable(tidyaov_plantgrowth)   term df sumsq meansq statistic p.value    group 2 3.76634 1.8831700 4.846088 0.01591  Residuals 27 10.49209 0.3885959 NA NA    Now, that we have a linear model this can be passed onto the emmeans package for equivalence and minimal effects testing.\n Mechanistic (Equivalence-MET) Analysis emm_plants = emmeans(mod_plantgrowth, trt.vs.ctrl1 ~ group, adjust = \u0026quot;none\u0026quot;) # Sets one group as the control to compare against the treatments # Note that adjust has to be set to \u0026quot;none\u0026quot; # otherwise the dunnett correction is applied knitr::kable(confint(emm_plants$contrasts, level = .9), caption = \u0026quot;Pairwise Comparisons with 90% C.I.\u0026quot;)  Table 1: Pairwise Comparisons with 90% C.I.  contrast estimate SE df lower.CL upper.CL    trt1 - ctrl -0.371 0.2787816 27 -0.8458455 0.1038455  trt2 - ctrl 0.494 0.2787816 27 0.0191545 0.9688455    #Equivalence Test emm_equivalence = test(emm_plants, delta = 1, adjust = \u0026quot;none\u0026quot;) knitr::kable(emm_equivalence$contrasts, caption = \u0026quot;Equivalence Tests\u0026quot;)  Table 2: Equivalence Tests  contrast estimate SE df t.ratio p.value    trt1 - ctrl -0.371 0.2787816 27 -2.256246 0.0161798  trt2 - ctrl 0.494 0.2787816 27 -1.815041 0.0403211    If we check the 90% confidence intervals, we can see that the upper limit (UL) is lower than the upper equivalence bound, but greater than the lower limit (LL) of the equivalence bound indicating equivalence at an alpha of .05 at both bounds. Pairwise comparisons indicate that both treatments are statistically equivalent (at least at our prespecified SESOI; delta parameter in the test function). Notice that only 1 p-value is reported, emmeans completes equivalence testing by taking the absolute difference between groups.\n Equation emmeans appears to be using for equivalence testing: Where M1 and M2 represent the means in condition 1 and condition 2 respectively, and represents a symmetrical equivalence bound, and SEM is the standard error of the mean.\nAlso, this is a one-tailed t-test:\nNot a two-tailed test:\nWhile it is unnecessary given the equivalence tests results, letâs see how we could perform the METs in both directions (positive and negative).\n#Minimal Effects Test: Positive emm_MET = test(emm_plants, null = 1, adjust = \u0026quot;none\u0026quot;, side = \u0026quot;\u0026gt;\u0026quot;) knitr::kable(emm_MET$contrasts, caption = \u0026quot;Minimal Effects Test: Positive\u0026quot;)  Table 3: Minimal Effects Test: Positive  contrast estimate SE df null t.ratio p.value    trt1 - ctrl -0.371 0.2787816 27 1 -4.917828 0.9999810  trt2 - ctrl 0.494 0.2787816 27 1 -1.815041 0.9596789    #Minimal Effects Test: Negative emm_MET = test(emm_plants, null = -1, adjust = \u0026quot;none\u0026quot;, side = \u0026quot;\u0026lt;\u0026quot;) knitr::kable(emm_MET$contrasts, caption = \u0026quot;Minimal Effects Test: Negative\u0026quot;)  Table 4: Minimal Effects Test: Negative  contrast estimate SE df null t.ratio p.value    trt1 - ctrl -0.371 0.2787816 27 -1 2.256246 0.9838202  trt2 - ctrl 0.494 0.2787816 27 -1 5.359034 0.9999942    The conclusions from a âmechanisticâ inference: Both treatments, compared to control, are moderately compatible with equivalence\n Clinical (MET \u0026amp; Non-Inferiority Analysis) The data can also be interpreted with the âclinical MBIâ approach which essentially boils down to a strict (low alpha; default = .005) and a more lax MET for benefit (high alpha; default = .25). In any case, individual researchers should set the alpha-level a priori and justify this decision (Lakens et al. 2018; âJustify Your Alpha by Minimizing or Balancing Error Rate,â n.d.).\nFor simplicity letâs keep the defaults for this analysis.\nFirst, we need to perform the non-inferiority tests. Luckily this is easy with emmeans.\n#Non-Inferiority Test emm_nonif = test(emm_plants, delta = 1, adjust = \u0026quot;none\u0026quot;, side = \u0026quot;noninferiority\u0026quot;) knitr::kable(emm_nonif$contrasts, caption = \u0026quot;Clinical Non-Inferiority\u0026quot;)  Table 5: Clinical Non-Inferiority  contrast estimate SE df t.ratio p.value    trt1 - ctrl -0.371 0.2787816 27 2.256246 0.0161798  trt2 - ctrl 0.494 0.2787816 27 5.359034 0.0000058    Treatment 1 (trt1) is only moderately compatible (given our predetermined alpha) with non-inferiority, but treatment 2 is strongly compatible (p \u0026lt; .005) with non-inferiority.\nNow we can perform a MET for the benefit, but notice how the use of the test function has changed. Now, we call the null and side parameters to set the threshold and direction of the statistical test. In this case we can keep null as the same value since we are testing a positive effect and side is set to â\u0026gt;â to indicate we are testing for superiority.\n#Minimal Effects Test emm_nonif = test(emm_plants, null = 1, adjust = \u0026quot;none\u0026quot;, side = \u0026quot;\u0026gt;\u0026quot;) knitr::kable(emm_nonif$contrasts, caption = \u0026quot;Clinical MET\u0026quot;)  Table 6: Clinical MET  contrast estimate SE df null t.ratio p.value    trt1 - ctrl -0.371 0.2787816 27 1 -4.917828 0.9999810  trt2 - ctrl 0.494 0.2787816 27 1 -1.815041 0.9596789    Conclusion: Do not use trt1 because we cannot assume non-inferiority. However, we can use trt2, which is compatible with non-inferiority, despite no evidence of any meaningful benefit.\n Analysis of ToothGrowth Data Again, we will need to add an âidâ column to the ToothGrowth dataset and then build the ANOVA model using afex. Notice this time there is a interaction in the ANOVA. Also, in this case, we believe a difference of 3 units in len to be the SESOI.\nToothGrowth = ToothGrowth %\u0026gt;% dplyr::mutate(id = rownames(ToothGrowth)) mod_Toothgrowth = afex::aov_car(len ~ supp*dose + Error(id), data = ToothGrowth) ## Converting to factor: dose ## Contrasts set to contr.sum for the following variables: supp, dose tidyaov_Toothgrowth = broom::tidy(mod_Toothgrowth$aov) knitr::kable(tidyaov_Toothgrowth)   term df sumsq meansq statistic p.value    supp 1 205.350 205.35000 15.571979 0.0002312  dose 2 2426.434 1213.21717 91.999965 0.0000000  supp:dose 2 108.319 54.15950 4.106991 0.0218603  Residuals 54 712.106 13.18715 NA NA    Now that we have a linear model this can be passed onto the emmeans package for equivalence and minimal effects testing.\n Mechanistic (Equivalence-MET) Analysis Compare Dosage  First, we want to compare Vitamin C dosage within each delivery method (VC or OJ) to see its effect on tooth growth.\nemm_Tooths = emmeans(mod_Toothgrowth, revpairwise ~ dose|supp, adjust = \u0026quot;none\u0026quot;) # Pairwise comparisions within each treatment across dosages # Note that adjust has to be set to \u0026quot;none\u0026quot; # otherwise the dunnett correction is applied knitr::kable(confint(emm_Tooths$contrasts, level = .9), caption = \u0026quot;Pairwise Comparisons with 90% C.I.\u0026quot;)  Table 7: Pairwise Comparisons with 90% C.I.  contrast supp estimate SE df lower.CL upper.CL    1 - 0.5 OJ 9.47 1.624016 54 6.752103 12.187897  2 - 0.5 OJ 12.83 1.624016 54 10.112103 15.547897  2 - 1 OJ 3.36 1.624016 54 0.642103 6.077897  1 - 0.5 VC 8.79 1.624016 54 6.072103 11.507897  2 - 0.5 VC 18.16 1.624016 54 15.442103 20.877897  2 - 1 VC 9.37 1.624016 54 6.652103 12.087897    #Equivalence Test emm_equivalence = test(emm_Tooths, delta = 3, adjust = \u0026quot;none\u0026quot;) knitr::kable(emm_equivalence$contrasts, caption = \u0026quot;Equivalence Tests\u0026quot;)  Table 7: Equivalence Tests  contrast supp estimate SE df t.ratio p.value    1 - 0.5 OJ 9.47 1.624016 54 3.9839496 0.9998977  2 - 0.5 OJ 12.83 1.624016 54 6.0528941 0.9999999  2 - 1 OJ 3.36 1.624016 54 0.2216726 0.5872975  1 - 0.5 VC 8.79 1.624016 54 3.5652347 0.9996148  2 - 0.5 VC 18.16 1.624016 54 9.3348805 1.0000000  2 - 1 VC 9.37 1.624016 54 3.9223739 0.9998752    If we check the 90% confidence intervals, we can see that the lower limit (LL) is higher than the upper equivalence bound, in all but one condition, indicating non-equivalence at an alpha of .05 at both bounds. Pairwise comparisons indicate that none of the doses in either treatment can be considered equivalent.\nNow, letâs perform the METs in both directions (positive and negative).\n#Minimal Effects Test: Positive emm_MET = test(emm_Tooths, null = 3, adjust = \u0026quot;none\u0026quot;, side = \u0026quot;\u0026gt;\u0026quot;) knitr::kable(emm_MET$contrasts, caption = \u0026quot;Minimal Effects Test: Positive\u0026quot;)  Table 8: Minimal Effects Test: Positive  contrast supp estimate SE df null t.ratio p.value    1 - 0.5 OJ 9.47 1.624016 54 3 3.9839496 0.0001023  2 - 0.5 OJ 12.83 1.624016 54 3 6.0528941 0.0000001  2 - 1 OJ 3.36 1.624016 54 3 0.2216726 0.4127025  1 - 0.5 VC 8.79 1.624016 54 3 3.5652347 0.0003852  2 - 0.5 VC 18.16 1.624016 54 3 9.3348805 0.0000000  2 - 1 VC 9.37 1.624016 54 3 3.9223739 0.0001248    #Minimal Effects Test: Negative emm_MET = test(emm_Tooths, null = -3, adjust = \u0026quot;none\u0026quot;, side = \u0026quot;\u0026lt;\u0026quot;) knitr::kable(emm_MET$contrasts, caption = \u0026quot;Minimal Effects Test: Negative\u0026quot;)  Table 8: Minimal Effects Test: Negative  contrast supp estimate SE df null t.ratio p.value    1 - 0.5 OJ 9.47 1.624016 54 -3 7.678493 1.0000000  2 - 0.5 OJ 12.83 1.624016 54 -3 9.747438 1.0000000  2 - 1 OJ 3.36 1.624016 54 -3 3.916216 0.9998727  1 - 0.5 VC 8.79 1.624016 54 -3 7.259778 1.0000000  2 - 0.5 VC 18.16 1.624016 54 -3 13.029424 1.0000000  2 - 1 VC 9.37 1.624016 54 -3 7.616918 1.0000000    We see that the data, in almost all conditions, is highly compatible with the hypothesis that a higher dosage results in a meaningful positive effect. However, it is inconclusive (non-equivalent and non-positive) if increasing dosage with OJ to 2 from 1 improves tooth growth.\nThe conclusions from a âmechanisticâ inference: Increasing dosage of OJ or VC results in increased tooth growth, but it is inconclusive if increasing OJ dosage (from 1 to 2) results in a meaningful improvement.\nCompare Delivery Methods  You may want to compare each delivery method at the specified doses. To do so, you simply flip the order of the factors in emmeans.\nemm_Tooths = emmeans(mod_Toothgrowth, revpairwise ~ supp|dose, adjust = \u0026quot;none\u0026quot;) knitr::kable(confint(emm_Tooths$contrasts, level = .9), caption = \u0026quot;Pairwise Comparisons with 90% C.I.\u0026quot;)  Table 9: Pairwise Comparisons with 90% C.I.  contrast dose estimate SE df lower.CL upper.CL    VC - OJ 0.5 -5.25 1.624016 54 -7.967897 -2.532103  VC - OJ 1 -5.93 1.624016 54 -8.647897 -3.212103  VC - OJ 2 0.08 1.624016 54 -2.637897 2.797897    #Equivalence Test emm_equivalence = test(emm_Tooths, delta = 3, adjust = \u0026quot;none\u0026quot;) knitr::kable(emm_equivalence$contrasts, caption = \u0026quot;Equivalence Tests\u0026quot;)  Table 9: Equivalence Tests  contrast dose estimate SE df t.ratio p.value    VC - OJ 0.5 -5.25 1.624016 54 1.385454 0.9141950  VC - OJ 1 -5.93 1.624016 54 1.804169 0.9616084  VC - OJ 2 0.08 1.624016 54 -1.798011 0.0388832    #Minimal Effects Test: Positive emm_MET = test(emm_Tooths, null = 3, adjust = \u0026quot;none\u0026quot;, side = \u0026quot;\u0026gt;\u0026quot;) knitr::kable(emm_MET$contrasts, caption = \u0026quot;Minimal Effects Test: Positive\u0026quot;)  Table 9: Minimal Effects Test: Positive  contrast dose estimate SE df null t.ratio p.value    VC - OJ 0.5 -5.25 1.624016 54 3 -5.079998 0.9999976  VC - OJ 1 -5.93 1.624016 54 3 -5.498713 0.9999995  VC - OJ 2 0.08 1.624016 54 3 -1.798011 0.9611168    #Minimal Effects Test: Negative emm_MET = test(emm_Tooths, null = -3, adjust = \u0026quot;none\u0026quot;, side = \u0026quot;\u0026lt;\u0026quot;) knitr::kable(emm_MET$contrasts, caption = \u0026quot;Minimal Effects Test: Negative\u0026quot;)  Table 9: Minimal Effects Test: Negative  contrast dose estimate SE df null t.ratio p.value    VC - OJ 0.5 -5.25 1.624016 54 -3 -1.385454 0.0858050  VC - OJ 1 -5.93 1.624016 54 -3 -1.804169 0.0383916  VC - OJ 2 0.08 1.624016 54 -3 1.896532 0.9683779    Conclusion: the data is weakly compatible with a negative effect of VC at the lower 2 doses, but is moderately compatible with equivalence at the highest dosage.\n Clinical (MET \u0026amp; Non-Inferiority Analysis) For the âclinical MBIâ approach letâs again use the same alphas as before (non-inferiority: .005 and MET: .25)\nFor simplicity, letâs just compare the delivery methods at each dosage.\n#Non-Inferiority Test emm_nonif = test(emm_Tooths, delta = 3, adjust = \u0026quot;none\u0026quot;, side = \u0026quot;noninferiority\u0026quot;) knitr::kable(emm_nonif$contrasts, caption = \u0026quot;Clinical Non-Inferiority\u0026quot;)  Table 10: Clinical Non-Inferiority  contrast dose estimate SE df t.ratio p.value    VC - OJ 0.5 -5.25 1.624016 54 -1.385454 0.9141950  VC - OJ 1 -5.93 1.624016 54 -1.804169 0.9616084  VC - OJ 2 0.08 1.624016 54 1.896532 0.0316221    #Minimal Effects Test emm_nonif = test(emm_Tooths, null = 3, adjust = \u0026quot;none\u0026quot;, side = \u0026quot;\u0026gt;\u0026quot;) knitr::kable(emm_nonif$contrasts, caption = \u0026quot;Clinical MET\u0026quot;)  Table 10: Clinical MET  contrast dose estimate SE df null t.ratio p.value    VC - OJ 0.5 -5.25 1.624016 54 3 -5.079998 0.9999976  VC - OJ 1 -5.93 1.624016 54 3 -5.498713 0.9999995  VC - OJ 2 0.08 1.624016 54 3 -1.798011 0.9611168    In this case, VC fails to adequately demonstrate non-inferiority.\nConclusion: Do not use VC at any dosage as it does not demonstrate adequate non-inferiority to OJ, and failed to provide any evidence of having a meaningful positive effect.\n  Application in SAS For the most part this will be accomplished using SASâs PROC MIXED, but a number of procedures also support these functions (Kiernan et al. 2011). The only SAS procedure I would suggest not using is PROC GLM, as I do not believe SAS has done anything to update this procedure in quite some time. I see no advantage of using PROC GLM over PROC MIXED. For simplicity, I will only being doing one analysis for each dataset.\nImport Data First, you will need to export the data from R.\nwrite.csv(ToothGrowth, \u0026quot;tooth.csv\u0026quot;) write.csv(PlantGrowth, \u0026quot;plant.csv\u0026quot;) Now, we can import it into SAS with PROC IMPORT. Remember, to change the file path!\nPROC IMPORT OUT= WORK.plant DATAFILE= \u0026quot;C:\\Users\\aaron.caldwell\\Documents\\plant.csv\u0026quot; DBMS=CSV REPLACE; GETNAMES=YES; DATAROW=2; RUN; PROC IMPORT OUT= WORK.tooth DATAFILE= \u0026quot;C:\\Users\\aaron.caldwell\\Documents\\tooth.csv\u0026quot; DBMS=CSV REPLACE; GETNAMES=YES; DATAROW=2; RUN;  Analysis of PlantGrowth â Mechanistic (Equivalence-MET) Analysis In this scenario, we will consider a difference of 1 unit of weight to be the SESOI.\nNow, in SASâs PROC MIXED equivalence and minimal effects testing will be carried out via the LSMESTIMATE statement.\n /*Mechanistic MBI */ title \u0026quot;Mechanistic MBI: PlantGrowth\u0026quot;; PROC MIXED data=plant; class group; model weight = group; lsmeans group / CL; /*Gets all the means and CI for each condition*/ lsmestimate group \u0026quot;ctrl v trt1\u0026quot; [1, 1] [-1,2], /*The first number sets the contrast and the assigns the level of group*/ \u0026quot;ctrl v trt2\u0026quot; [1, 1] [-1,3] / TESTVALUE=-1 UPPER CL; /*Lower bound equivalence test*/ lsmestimate group \u0026quot;ctrl v trt1\u0026quot; [1, 1] [-1,2], \u0026quot;ctrl v trt2\u0026quot; [1, 1] [-1,3] / TESTVALUE=1 LOWER CL; /*Upper bound equivalence test*/ run; quit;  Figure 2. LSMESTIMATE Results for Equivalence Testing on Plant Data.\n If we check the confidence limits, we can see that the upper limit (UL) is lower than the upper equivalence bound, but greater than the lower limit (LL) of the equivalence bound indicating equivalence at an alpha of .05 at both bounds. Pairwise comparisons indicate that both treatments are statistically equivalent (at least at our prespecified SESOI set by the TESTVALUE parameter in the LSMESTIMATE statement). Notice that only 2 p-values are reported, unlike emmeans we must perform an upper bound and lower bound test. We only infer equivalence if the highest p-value for each comparison is less than the predetermined alpha.\nThe conclusions from a âmechanisticâ inference: Both treatments, compared to control, are moderately compatible with equivalence\n ToothGrowth Clinical (MET \u0026amp; Non-Inferiority) Analysis This is fairly straight forward in SAS. All we need to do is modify the upper bound TESTVALUE and modify the alpha. For the âclinical MBIâ approach letâs change the alpha for the MET (non-inferiority: .005 and MET: .2).\n/*Clinical MBI */ title \u0026quot;Clinical MBI: ToothGrowth\u0026quot;; PROC MIXED data=tooth; class supp dose; model len = supp|dose; lsmeans supp*dose / CL; /*Gets all the means and CI for each condition*/ lsmestimate supp*dose \u0026quot;OJ vs VC @ 0.5 mg dose\u0026quot; [-1, 1 3] [1, 2 3], \u0026quot;OJ vs VC @ 1 mg dose\u0026quot; [-1, 1 1] [1, 2 1], \u0026quot;OJ vs VC @ 2 mg dose\u0026quot; [-1, 1 2] [1, 2 2] / TESTVALUE=-1 CL UPPER alpha=.005; lsmestimate supp*dose \u0026quot;OJ vs VC @ 0.5 mg dose\u0026quot; [-1, 1 3] [1, 2 3], \u0026quot;OJ vs VC @ 1 mg dose\u0026quot; [-1, 1 1] [1, 2 1], \u0026quot;OJ vs VC @ 2 mg dose\u0026quot; [-1, 1 2] [1, 2 2] / TESTVALUE=1 CL UPPER alpha=.2; run; quit;  For simplicity, letâs just compare the delivery methods at each dosage.\nFigure 3. LSMESTIMATE Results for Equivalence Testing on Tooth Data.\n In this case, VC fails to adequately demonstrate non-inferiority.\nConclusion: Do not use VC at any dosage as it does not demonstrate adequate non-inferiority to OJ, and failed to provide any evidence of having a meaningful positive effect.\n  Writing your Methods One of the more frustrating problems I noticed with research reporting MBI in the past was the lack of detail in their methods sections about the statistical methods they utilized. Frankly this is a problem in most sport and exercise science manuscripts, not just those that utilized MBI. Therefore, I have created a short list of items that should always be included if you are using this approach.\nNote what types of hypotheses you are testing.   If you are using the âmechanisticâ approach: note that you are simply performing an equivalence/MET test If you are using the âclincalâ approach: note that you are using a non-inferiority test and a minimal effects test  State the alpha level(s)   Even if you are using the âcompatibilityâ bounds outlined by Aisbett, Lakens, and Sainani (2020) you should directly state the alpha levels for used within your manuscript. Justifying your alpha can be difficult and should be done a priori. Most likely, this can be accomplished when you are planning your sample size for data collection by balancing your type 1 and type 2 error using a compromise power analysis.  There are blog posts from minitab and Lakens that may be helpful here.   State your smallest effect size(s) of interest (SESOI)   In most cases of MBI users have defaulted to a difference of 0.2 standard deviations (Cohenâs d = 0.2) I would encourage researchers to have justification for their SESOI whether based on practitioner preferences (e.g., âcoaches have stated an interest in an effect of X magnitudeâ) or based on empirical evidence. -For empirical justifications, I suggest reading the DETLA2 guidelines (Cook et al. 2018).  Note and cite what statistical software and programs you used to analyze the data.   Try to be specific and include version number  This is important because as the software is updated some calculations may change.    Concluding Remarks Any researcher is capable of performing the appropriate equivalence, MET, and non-inferiority tests in R or SAS. As I have documented, making a âmagnitude based inferenceâ is fairly simple and straight forward procedure when it is viewed through these lenses. All of these approaches (equivalence, MET, and non-inferiority tests) in the scenarios I have outlined are special cases of a one-tailed t-test. Researchers who would like to adopt this approach should read the work by Aisbett, Lakens, and Sainani (2020) to ensure they fully understand the statistical framework. Both Batterham \u0026amp; Hopkins, the creators of MBI, should be also commended for moving the conversation surrounding statistical inference in sport science from a focus on ânil hypothesesâ to a focus on the magnitude of the effect size. However, I would strongly encourage all sports scientists that have used magnitude based inference in the past to adopt this straightforward frequentist approach or adopt a fully Bayesian approach to inference (Ravenzwaaij et al. 2019).\n Questions? If you have any questions, please feel free to contact me.\n References Aisbett, Janet, Daniel Lakens, and Kristin Sainani. 2020. âMagnitude Based Inference in Relation to One-Sided Hypotheses Testing Procedures,â May. https://doi.org/10.31236/osf.io/pn9s3.\n Amrhein, Valentin, David Trafimow, and Sander Greenland. 2019. âInferential Statistics as Descriptive Statistics: There Is No Replication Crisis If We Donât Expect Replication.â The American Statistician 73 (sup1): 262â70. https://doi.org/10.1080/00031305.2018.1543137.\n Batterham, Alan M., and William G. Hopkins. 2006. âMaking Meaningful Inferences About Magnitudes.â International Journal of Sports Physiology and Performance 1 (1): 50â57. https://doi.org/10.1123/ijspp.1.1.50.\n Chow, Zad R., and Sander Greenland. 2019. âSemantic and Cognitive Tools to Aid Statistical Inference: Replace Confidence and Significance by Compatibility and Surprise.â http://arxiv.org/abs/1909.08579.\n Cook, Jonathan A., Steven A. Julious, William Sones, Lisa V. Hampson, Catherine Hewitt, Jesse A. Berlin, Deborah Ashby, et al. 2018. âChoosing the Target Difference (\u0026amp;Ldquo\\(\\mathsemicolon\\)effect Size\u0026amp;rdquo\\(\\mathsemicolon\\)) for a Randomised Controlled Trial - DELTA\\(\\less\\)sup\\(\\greater\\)2\\(\\less\\)/Sup\\(\\greater\\)\u0026amp;nbsp\\(\\mathsemicolon\\)Guidance,â August. https://doi.org/10.20944/preprints201808.0521.v1.\n Greenland, Sander, and Zad R. Chow. 2019. âTo Aid Statistical Inference, Emphasize Unconditional Descriptions of Statistics.â http://arxiv.org/abs/1909.08583.\n âJustify Your Alpha by Minimizing or Balancing Error Rate.â n.d. http://http://daniellakens.blogspot.com/2019/05/justifying-your-alpha-by-minimizing-or.html.\n Kiernan, Kathleen, Randy Tobias, Phil Gibbs, and Jill Tao. 2011. âCONTRAST and Estimate Statements Made Easy: The Lsmestimate Statement.â SAS Global Forum 2011 (351): 1â19. https://support.sas.com/resources/papers/proceedings11/351-2011.pdf.\n Lakens, Daniel, Federico G. Adolfi, Casper J. Albers, Farid Anvari, Matthew A. J. Apps, Shlomo E. Argamon, Thom Baguley, et al. 2018. âJustify Your Alpha.â Nature Human Behaviour 2 (3): 168â71. https://doi.org/10.1038/s41562-018-0311-x.\n Lakens, DaniÃ«l, Anne M. Scheel, and Peder M. Isager. 2018a. âEquivalence Testing for Psychological Research: A Tutorial.â Advances in Methods and Practices in Psychological Science 1 (2): 259â69. https://doi.org/10.1177/2515245918770963.\n âââ. 2018b. âEquivalence Testing for Psychological Research: A Tutorial.â Advances in Methods and Practices in Psychological Science 1 (2): 259â69. https://doi.org/10.1177/2515245918770963.\n Lenth, Russell. 2020. Emmeans: Estimated Marginal Means, Aka Least-Squares Means. https://CRAN.R-project.org/package=emmeans.\n Lohse, Keith, Kristin Sainani, J. Andrew Taylor, Michael Lloyd Butson, Emma Knight, and Andrew Vickers. 2020. âSystematic Review of the Use of âMagnitude-Based Inferenceâ in Sports Science and Medicine.â Center for Open Science. https://doi.org/10.31236/osf.io/wugcr.\n Peterson, Kyle, and Aaron Caldwell. 2019. Mbir: Magnitude-Based Inferences. https://CRAN.R-project.org/package=mbir.\n Rafi, Zad, and Andrew D. Vigotsky. 2020. concurve: Computes and Plots Compatibility (Confidence) Intervals, P-Values, S-Values, \u0026amp; Likelihood Intervals to Form Consonance, Surprisal, \u0026amp; Likelihood Functions. https://CRAN.R-project.org/package=concurve.\n Ravenzwaaij, Don van, Rei Monden, Jorge N. Tendeiro, and John P. A. Ioannidis. 2019. âBayes Factors for Superiority, Non-Inferiority, and Equivalence Designs.â BMC Medical Research Methodology 19 (1). https://doi.org/10.1186/s12874-019-0699-7.\n Robinson, David, and Alex Hayes. 2020. Broom: Convert Statistical Analysis Objects into Tidy Tibbles. https://CRAN.R-project.org/package=broom.\n Sainani, Krisitin. 2018. âThe Problem with âMagnitude-Based Inferenceâ.â Medicine \u0026amp; Science in Sports \u0026amp; Exercise 50 (10): 2166â76. https://doi.org/10.1249/mss.0000000000001645.\n Sainani, Kristin L., Keith R. Lohse, Paul Remy Jones, and Andrew Vickers. 2019. âMagnitude-Based Inference Is Not Bayesian and Is Not a Valid Method of Inference.â Scandinavian Journal of Medicine \u0026amp; Science in Sports 29 (9): 1428â36. https://doi.org/10.1111/sms.13491.\n Singmann, Henrik, Ben Bolker, Jake Westfall, Frederik Aust, and Mattan S. Ben-Shachar. 2020. Afex: Analysis of Factorial Experiments. https://CRAN.R-project.org/package=afex.\n Wickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy DâAgostino McGowan, Romain FranÃ§ois, Garrett Grolemund, et al. 2019. âWelcome to the tidyverse.â Journal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686.\n   ","date":1588550400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588623418,"objectID":"5ed0dd805d51f20d74384338d10c0292","permalink":"https://aaroncaldwell.us/post/new-mbi/","publishdate":"2020-05-04T00:00:00Z","relpermalink":"/post/new-mbi/","section":"post","summary":"Updated on: 2020-05-05\nIntroduction There have been a number of criticisms of âmagnitude-based inferencesâ (Batterham and Hopkins 2006) which is a unique approach to statistics in the sport and exercise science community. As an author of the mbir package (Peterson and Caldwell 2019), I have been watching this all develop closely. What is clear from the criticisms is that MBI has some fatal flaws directly related to the sample size estimations and the interpretations of the probabilities that the MBI spreadsheets provide (Lohse et al.","tags":["magnitude based inference","R","SAS","statistics","MBI"],"title":"Magnitude Based Inference in R and SAS","type":"post"},{"authors":null,"categories":null,"content":"","date":1573430400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573430400,"objectID":"4f686f40240bc2e3ddb0f051ec60dc70","permalink":"https://aaroncaldwell.us/project/shinyexactapp/","publishdate":"2019-11-11T00:00:00Z","relpermalink":"/project/shinyexactapp/","section":"project","summary":"R package for developed for power analysis with Daniel Lakens","tags":["R","Statistics","Shiny"],"title":"Exact Simulation Power Shiny App","type":"project"},{"authors":null,"categories":null,"content":"","date":1573430400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573430400,"objectID":"56b3faff82773ed5957c8c59f86ef692","permalink":"https://aaroncaldwell.us/project/shinypowerapp/","publishdate":"2019-11-11T00:00:00Z","relpermalink":"/project/shinypowerapp/","section":"project","summary":"Shiny app that performs Monte Carlo simulations to estimate power for ANOVAs","tags":["R","Statistics","Shiny"],"title":"Monte Carlo Power Shiny App","type":"project"},{"authors":null,"categories":null,"content":"","date":1573430400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573430400,"objectID":"2dca668855d782624138c64bf71322fa","permalink":"https://aaroncaldwell.us/project/superpowerrpackage/","publishdate":"2019-11-11T00:00:00Z","relpermalink":"/project/superpowerrpackage/","section":"project","summary":"R package for developed for power analysis with Daniel Lakens","tags":["R","Statistics"],"title":"Superpower R package","type":"project"},{"authors":null,"categories":["R","information"],"content":"This is my personal blog area on my website. This is a place for me to express my personal thoughts in a relaxed nature. Most of my writing has been published in academic journals, and most of it is difficult to read and well boring. My hope is this blog will provide me an outlet to communicate directly and informally than my academic writing.\nWhat to expect Well, this is the boring part. I am a nerd with an interest in physiology and statistics. That means my blog will mostly focus on those two things. If that is what you are interested then wonderful! I hope you find my blog useful.\n","date":1573430400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573430400,"objectID":"e902771f48cbc9203cdbe443ea8b6f9c","permalink":"https://aaroncaldwell.us/post/welcome-to-my-blog/","publishdate":"2019-11-11T00:00:00Z","relpermalink":"/post/welcome-to-my-blog/","section":"post","summary":"This is my personal blog area on my website. This is a place for me to express my personal thoughts in a relaxed nature. Most of my writing has been published in academic journals, and most of it is difficult to read and well boring. My hope is this blog will provide me an outlet to communicate directly and informally than my academic writing.\nWhat to expect Well, this is the boring part.","tags":[],"title":"Welcome to my blog","type":"post"},{"authors":null,"categories":null,"content":"Citable as:\nAaron R. Caldwell (2019) Basics of Statistics for Exercise Science. Guest lecture at UC-San Marcos\n","date":1573344000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573344000,"objectID":"3cc331df06f675dd36a404ca6de7fd75","permalink":"https://aaroncaldwell.us/talk/basicstats/","publishdate":"2019-11-10T00:00:00Z","relpermalink":"/talk/basicstats/","section":"talk","summary":"Citable as:\nAaron R. Caldwell (2019) Basics of Statistics for Exercise Science. Guest lecture at UC-San Marcos","tags":null,"title":"Basics of Statistics","type":"talk"},{"authors":["Matthew S Tenan, Andrew Vigotsky, Aaron Caldwell"],"categories":null,"content":"Letter-to-editor on responder-non-responder analysis proposed in Sports Medicine\nCiteable as:\nTenan, M., Vigotsky, A. D., \u0026amp; Caldwell, A. R. (2019, October 1). On the Statistical Properties of the Dankel-Loenneke Method. SportRxiv\n","date":1569888000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569888000,"objectID":"320627b4c4cf90fff771498fd9903353","permalink":"https://aaroncaldwell.us/publication/responderslte/","publishdate":"2019-10-01T00:00:00Z","relpermalink":"/publication/responderslte/","section":"publication","summary":"Dankel \u0026 Loenneke (2019) recently presented a new approach to identifying subgroups in parallel group study designs. Here, we briefly discuss our statistical  concerns with proposed approach. We reveal that the error rates of the Danke-Loenneke approach are much higher than the claimed 5%, and that these error rates are dependent on numerous factors, including sample size, effect variance, and random error. The Dankel-Loenneke method has poor statistical properties; as such, we suggest that the method not be used and the manuscript constitutes an honest error per the Committee on Publication Ethics (COPE) guidelines.","tags":null,"title":"On the Statistical Properties of the Dankel-Loenneke Method","type":"publication"},{"authors":["Aaron R. Caldwell, Samuel Cheuvront"],"categories":null,"content":"This was a invited review for the journal Temperature. We attempted to create a review that would guide authors through the common statistical concerns that they should address with every study and in the eventual manuscript.\nCiteable as:\nCaldwell, A. R., \u0026amp; Cheuvront, S. N. (2019). Basic statistical considerations for physiology: The journal Temperature toolbox. Temperature, 1-30. https://doi.org/10.1080/23328940.2019.1624131\n","date":1559001600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559001600,"objectID":"4162f7a296bd5b3bb0f3931ffcf4684b","permalink":"https://aaroncaldwell.us/publication/temp_review/","publishdate":"2019-05-28T00:00:00Z","relpermalink":"/publication/temp_review/","section":"publication","summary":"The average environmental and occupational physiologist may find statistics are difficult to interpret and use since their formal training in statistics is limited. Unfortunately, poor statistical practices can generate erroneous or at least misleading results and distorts the evidence in the scientific literature. These problems are exacerbated when statistics are used as thoughtless ritual that is performed after the data are collected. The situation is worsened when statistics are then treated as strict judgements about the data (i.e., significant versus non-significant) without a thought given to how these statistics were calculated or their practical meaning. We propose that researchers should consider statistics at every step of the research process whether that be the designing of experiments, collecting data, analysing the data or disseminating the results. When statistics are considered as an integral part of the research process, from start to finish, several problematic practices can be mitigated. Further, proper practices in disseminating the results of a study can greatly improve the quality of the literature. Within this review, we have included a number of reminders and statistical questions researchers should answer throughout the scientific process. Rather than treat statistics as a strict rule following procedure we hope that readers will use this review to stimulate a discussion around their current practices and attempt to improve them.","tags":null,"title":"Basic statistical considerations for physiology: The journal Temperature toolbox","type":"publication"},{"authors":["Daniel Lakens","Aaron R. Caldwell"],"categories":null,"content":"A tutorial article on using the Superpower R package.\nCiteable as:\nLakens, D., \u0026amp; Caldwell, A. R. (2019). Simulation-Based Power-Analysis for Factorial ANOVA Designs. Advances in Methods and Practices in Psychological Science https://doi.org/10.31234/osf.io/baxsf\n","date":1558396800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558396800,"objectID":"9a0373e3288ead320c7c32568b94a89b","permalink":"https://aaroncaldwell.us/publication/anova_simulation/","publishdate":"2019-05-21T00:00:00Z","relpermalink":"/publication/anova_simulation/","section":"publication","summary":"Researchers often rely on analysis of variance (ANOVA) when they report results of experiments. To ensure a study is adequately powered to yield informative results when performing an ANOVA, researchers can perform an a-priori power analysis. However, power analysis for factorial ANOVA designs is often a challenge. Current software solutions do not allow power analyses for complex designs with several within-subject factors. Moreover, power analyses often need partial eta-squared or Cohen's *f* as input, but these effect sizes are not intuitive and do not generalize to different experimental designs. We have created the R package Superpower and online Shiny apps to enable researchers without extensive programming experience to perform simulation-based power analysis for ANOVA designs of up to three within- or between-subject factors. Predicted effects are entered by specifying means, standard deviations, and for within-subject factors the correlations. The simulation provides the statistical power for all ANOVA main effects, interactions, and individual comparisons, and allows researchers to correct for multiple comparisons. The software can plot power across a range of sample sizes, can control error rates for multiple comparisons, and can compute power when the homogeneity or sphericity assumptions are violated. This tutorial will demonstrate how to perform a-priori power analysis to design informative studies for main effects, interactions, and individual comparisons, and highlights important factors that determine the statistical power for factorial ANOVA designs.","tags":null,"title":"Simulation-Based Power-Analysis for Factorial ANOVA Designs","type":"publication"},{"authors":["Aaron R. Caldwell, Andrew D. Vigotsky, et al."],"categories":null,"content":"A short opinion article on why sport and exercise science journals should adopt the Registered Reports format.\nCiteable as:\nCaldwell, A. R., Vigotsky, A. D., Tenan, M. S., Radel, R., Mellor, D. T., Kreutzer, A., Lahart, I. M., Mills, J. P., Boisgontier, M. P., \u0026amp; Consortium for Transparency in Exercise Science (COTES) Collaborators (2020). Moving Sport and Exercise Science Forward: A Call for the Adoption of More Transparent Research Practices. Sports Medicine (Auckland, N.Z.), 50(3), 449â459. https://doi.org/10.1007/s40279-019-01227-1\n","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"646fbf1d8a3b489bbdcfa848af017e2f","permalink":"https://aaroncaldwell.us/publication/rrcall/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/publication/rrcall/","section":"publication","summary":"The primary means for disseminating sport and exercise science research is currently through journal articles. However, not all studies, especially those with null findings, make it to formal publication. This publication bias towards positive findings may contribute to questionable research practices. Preregistration is a solution to prevent the publication of distorted evidence resulting from this system. This process asks authors to register their hypotheses and methods before data collection on a publicly available repository or by submitting a Registered Report. In the Registered Reports format, authors submit a Stage 1 manuscript to a participating journal that includes an introduction, methods, and any pilot data indicating the exploratory or confirmatory nature of the study. After a Stage 1 peer review, the manuscript can then be offered in-principle acceptance, rejected, or sent back for revisions to improve the quality of the study. If accepted, the project is guaranteed publication, assuming the authors follow the data collection and analysis protocol. After data collection, authors re-submit a Stage 2 manuscript that includes the results and discussion, and the study is evaluated on clarity and conformity with the planned analysis. In its final form, Registered Reports appear almost identical to a typical publication, but give readers confidence that the hypotheses and main analyses are less susceptible to bias from questionable research practices. From this perspective, we argue that inclusion of Registered Reports by researchers and journals will improve the transparency, replicability, and trust in sport and exercise science research.","tags":null,"title":"Moving Sport and Exercise Science Forward: A Call for the Adoption of More Transparent Research Practices","type":"publication"},{"authors":["Matthew A. Tucker, Aaron R. Caldwell, Matthew S. Ganio"],"categories":null,"content":"Citeable as:\nTucker, M. A., Caldwell, A. R., \u0026amp; Ganio, M. S. (2019). Adequacy of Daily Fluid Intake Volume Can Be Identified From Urinary Frequency and Perceived Thirst in Healthy Adults. Journal of the American College of Nutrition, 1. http://dx.doi.org/10.1080/07315724.2019.1639566\n","date":1534377600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1534377600,"objectID":"8f8b6db9e96a93424db5fb7ad4dec99b","permalink":"https://aaroncaldwell.us/publication/void_fluid_intake/","publishdate":"2018-08-16T00:00:00Z","relpermalink":"/publication/void_fluid_intake/","section":"publication","summary":"Objective: Achieving and maintaining an optimal level of hydration has significant implications for both acute and chronic health, yet many hydration assessments are not feasible for the general public. Urinary frequency (UF) is a reliable method to self-assess hydration status in healthy individuals, and thirst can provide additional sensory information on adequacy of daily fluid intake volume (DFI). However, threshold values for these indices to detect optimal hydration have not been determined. In this study, we sought to determine threshold values for 24-hour UF and perceived thirst that could accurately distinguish between optimal and suboptimal hydration states. Methods: Thirty-two healthy adults (age 22 Â± 3 years, body mass index 24.9Â± 4.1 kg/m2) collected urine over 24 hours on four separate occasions, where UF was recorded as well as thirst at each void using a numbered perceptual scale. Using urine osmolality as the criterion standard, all samples were either classified as representing an optimal (â¤500 mOsmÂ·kg-1) or suboptimal hydration status (500 mOsmÂ·kg-1). Results: A 24-hour UF â¤6 was able to detect suboptimal hydration with good accuracy (area under the curve [AUC] 0.815) and a 24-hour average perceived thirst rating  3 (a little thirsty) could detect it with reasonable accuracy (AUC 0.725). In addition, a UF â¤4 had a considerably higher positive likelihood ratio to detect suboptimal hydration versus a UF â¤6 (9.03 versus 2.18, respectively). Conclusions: These analyses suggest that individuals with a 24-hour UF â¤6 or perceiving themselves to be, on average, -a little thirsty- throughout the day are likely to be suboptimally hydrated and thus underconsuming an adequate DFI.","tags":null,"title":"Adequacy of Daily Fluid Intake Volume Can Be Identified From Urinary Frequency and Perceived Thirst in Healthy Adults","type":"publication"},{"authors":["Aaron R. Caldwell, Jenna Burchfield, Nicole E. Moyen, Matthew A. Tucker, Cory L. Butts, R.J. Elbin, Matthew S. Ganio"],"categories":null,"content":"Citeable as:\nCaldwell, A. R., Burchfield, J., Moyen, N. E., Tucker, M. A., Butts, C. L., Elbin, R. J., \u0026amp; Ganio, M. S. (2018). Obesity, but not hypohydration, mediates changes in mental task load during passive heating in females. PeerJ, 6, e5394. https://doi.org/10.7717/peerj.5394\n","date":1534377600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1534377600,"objectID":"2a85ff8d3553180b09f89e9a2e585f38","permalink":"https://aaroncaldwell.us/publication/obesity_heat/","publishdate":"2018-08-16T00:00:00Z","relpermalink":"/publication/obesity_heat/","section":"publication","summary":"Background:The independent effects of hypohydration and hyperthermia on cognition and mood is unclear since the two stresses often confound each other. Further, it is unknown if obese individuals have the same impairments during hyperthermia and hypohydration that is often observed in non-obese individuals. Methods:The current study was designed to assess the independent and combined effects of mild hypohydration and hyperthermia on cognition, mood, and mental task load in obese and non-obese females. Twenty-one healthy females participated in two passive heating trials, wherein they were either euhydrated or hypohydrated prior to and throughout passive heating. Cognition (ImPACT), mental task load (NASA-TLX), and mood (Brunel Mood Scale; BRUMS) were measured before and after a 1.0 Â°C increase in core temperature (TC). Results: After a 1.0 Â°C TC elevation, hypohydration resulted in greater (p 0.05). Hyperthermia, regardless of hydration status, impaired (â¼5 A.U) measures of memory-based cognition (verbal and visual memory), and increased mental task load, while worsening mood (p 0.05). Conclusion: These data indicate that hyperthermia independently impairs memory-based aspects of cognitive performance, mental task load, and leads to a negative mood state. Mild hypohydration did not exacerbate the effects of hyperthermia. However, obese individuals had increased mental task load during hyperthermia.","tags":null,"title":"Obesity, but not hypohydration, mediates changes in mental task load during passive heating in females","type":"publication"},{"authors":["Aaron R. Caldwell, Kaitlin M. Gallagher, Benjamin T. Harris, Megan E. Rosa-Caldwell, Marcus PayneBryce Daniels, Matthew S. Ganio"],"categories":null,"content":"Citeable as:\nCaldwell, A. R., Gallagher, K. M., Harris, B. T., Rosa-Caldwell, M. E., Payne, M., Daniels, B., \u0026amp; Ganio, M. S. (2018). Prolonged standing increases lower limb arterial stiffness. European journal of applied physiology, 118(10), 2249-2258. https://doi.org/10.1007/s00421-018-3956-2\n","date":1501718400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1501718400,"objectID":"01022dd5899d6da65b84dfa62cf8d5f7","permalink":"https://aaroncaldwell.us/publication/stif1/","publishdate":"2017-08-03T00:00:00Z","relpermalink":"/publication/stif1/","section":"publication","summary":"Purpose: Standing workstations have recently been promoted as a healthy alternative to sitting. However, it is unknown how prolonged standing affects arterial stiffness, a prognostic indicator of cardiovascular health. The purpose of this study was twofold: to observe changes in arterial stiffness, as assessed by pulse wave velocity (PWV), with a 2-h bout of standing, and to determine if short, intermittent walking bouts provide a comparative advantage to standing alone. Methods: Nineteen adults had arterial stiffness assessed by pulse wave velocity. Central (CPWV), upper peripheral (UPWV), and lower peripheral (LPWV) PWV were assessed before (supine), during standing (min 10, 60, and 120), and after (supine) the 2-h standing bout. In one trial, the participants stood at a standing desk immobile for 2 h. In the other trial, participants performed 5-min walking breaks after every 25 min of standing. Results: After 2-h of standing, supine (85.8Â±90.1 cm/s) and standing (303.4Â±390.2 cm/s), LPWV increased independent of trial (i.e., main effect of time; p0.05).Conclusions: These findings indicate that prolonged standing increases the measures of arterial stiffness and there is no evidence that walk breaks attenuate this response.","tags":null,"title":"Prolonged standing increases lower limb arterial stiffness","type":"publication"},{"authors":["Aaron R. Caldwell, Forrest B. Robinson, Matthew A. Tucker, Cash H. Arcement, Cory L. Butts, Brendon P. McDermott, Matthew S. Ganio"],"categories":null,"content":"Citeable as:\nCaldwell, A. R., Robinson, F. B., Tucker, M. A., Arcement, C. H., Butts, C. L., McDermott, B. P., \u0026amp; Ganio, M. S. (2017). Effect of passive heat stress and exercise in the heat on arterial stiffness. European journal of applied physiology, 117(8), 1679-1687. https://doi.org/10.1007/s00421-017-3658-1\n","date":1497657600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1497657600,"objectID":"421c6694da98467e619e23e34f4be908","permalink":"https://aaroncaldwell.us/publication/passiveheat_stiffness/","publishdate":"2017-06-17T00:00:00Z","relpermalink":"/publication/passiveheat_stiffness/","section":"publication","summary":"PURPOSE: Prior evidence indicates that acute heat stress and aerobic exercise independently reduce arterial stiffness. The combined effects of exercise and heat stress on PWV are unknown. The purpose of this study was to determine the effects of heat stress with passive heating and exercise in the heat on arterial stiffness. METHODS: Nine participants (n = 3 females, 47 Â± 11 years old; 24.1 Â± 2.8 kg/m2) completed four trials. In a control trial, participants rested supine (CON). In a passive heating trial (PH), participants were heated with a water-perfusion suit. In two other trials, participants cycled at ~50% of [Formula: see text] in a hot (~40 Â°C; HC trial) or cool (~15 Â°C; CC trial) environment. Arterial stiffness, measured by PWV, was obtained at baseline and after each intervention (immediately, 15, 30, 45, and 60 min post). Central PWV (C PWV) was assessed between the carotid/femoral artery sites. Upper and lower peripheral PWV was assessed using the radial/carotid (U PWV) and dorsalis pedis/femoral (L PWV) artery sites. The mean body temperature (T B) was calculated from the skin and rectal temperatures. RESULTS: No significant changes in T B were observed during the CON and CC trials. As expected, the PH and HC trials elevated T B 2.69 Â± 0.23 Â°C and 1.67 Â± 0.27 Â°C, respectively (p 0.05). However, in the PH trial, U PWV was reduced immediately (-107 Â± 81 cm/s) and 15 min (-93 Â± 82 cm/s) post-heating (p ","tags":null,"title":"Effect of passive heat stress and exercise in the heat on arterial stiffness.","type":"publication"},{"authors":null,"categories":null,"content":"Citable as:\nAaron R. Caldwell (2017) Measuring Sweat Gland Activation. Presentation at Experimental Biology 2017.\n","date":1492473600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1492473600,"objectID":"9859d6fc4de73ff7b2023eedf7182477","permalink":"https://aaroncaldwell.us/talk/sga/","publishdate":"2017-04-18T00:00:00Z","relpermalink":"/talk/sga/","section":"talk","summary":"Citable as:\nAaron R. Caldwell (2017) Measuring Sweat Gland Activation. Presentation at Experimental Biology 2017.","tags":null,"title":"Measuring Sweat Gland Activation","type":"talk"},{"authors":["Aaron R. Caldwell, Matthew A. Tucker, Jenna Burchfield, Nicole E. Moyen, Alf Z. Satterfield, Ashley Six, Brendon P. McDermott, Sean W. Mulvenon, Matthew S. Ganio"],"categories":null,"content":"A short paper looking at the effect of heat and hydration on central and peripheral arterial stiffness.\nCiteable as:\nCaldwell, A. R., Tucker, M. A., Burchfield, J., Moyen, N. E., Satterfield, A. A., Six, A., \u0026hellip; \u0026amp; Ganio, M. S. (2017). Hydration Status Influences the Measurement of Arterial Stiffness. Clinical Physiology and Functional Imaging, 38(3), 447.\n","date":1492387200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1492387200,"objectID":"1c586398b901d9922d11a2651771c459","permalink":"https://aaroncaldwell.us/publication/hydration_stiffness/","publishdate":"2017-04-17T00:00:00Z","relpermalink":"/publication/hydration_stiffness/","section":"publication","summary":"Consensus guidelines have attempted to standardize the measurement and interpretation of pulse wave velocity (PWV); however, guidelines have not addressed whether hydration status affects PWV. Moreover, multiple studies have utilized heat stress to reduce arterial stiffness which may lead to dehydration. This study utilized two experiments to investigate the effects of dehydration on PWV at rest and during passive heat stress. In experiment 1, subjects (n = 19) completed two trials, one in which they arrived euhydrated and one dehydrated (1Â·2[1Â·0]% body mass loss). In experiment 2, subjects (n = 11) began two trials euhydrated and in one trial did not receive water during heat stress, thus becoming dehydrated (1Â·6[0Â·6]% body mass loss); the other trial subjects remained euhydrated. Using Doppler ultrasound, carotid-to-femoral (central) and carotid-to-radial (peripheral) PWVs were measured. PWV was obtained at a normothermic baseline, and at a 0Â·5Â°C and 1Â°C elevation in rectal temperature (via passive heating). In experiment 1, baseline central PWV was significantly higher when euhydrated compared to dehydrated (628[95] versus 572[91] cm s-1 , respectively; P0Â·05). However, starting euhydrated and becoming dehydrated during heating in experiment 2 did not affect PWV measures (P0Â·05), and independent of hydration status peripheral PWV was reduced when rectal temperature was elevated 0Â·5Â°C (-74[45] cm s-1 ; P","tags":null,"title":"Hydration status influences the measurement of arterial stiffness.","type":"publication"},{"authors":["Aaron Caldwell, Matthew Tucker,  Cory Butts,  Brendon McDermott,  Jakob Vingren,  Laura Kunces,  Elaine Lee,  Colleen Munoz,  Keith Williamson,  Lawrence Armstrong,  Matthew Ganio"],"categories":null,"content":"My first, first author paper on a field study of the effects of caffeine on delayed onset muscle soreness.\nCiteable as:\nCaldwell, A. R., Tucker, M. A., Butts, C. L., McDermott, B. P., Vingren, J. L., Kunces, L. J., \u0026hellip; \u0026amp; Ganio, M. S. (2017). Effect of caffeine on perceived soreness and functionality following an endurance cycling event. Journal of strength and conditioning research, 31(3), 638-643. https://doi.org/10.1519/JSC.0000000000001608\n","date":1488326400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1488326400,"objectID":"3a2e52cd28d6c80cec0d9ff11fc90850","permalink":"https://aaroncaldwell.us/publication/caffeine/","publishdate":"2017-03-01T00:00:00Z","relpermalink":"/publication/caffeine/","section":"publication","summary":"Caffeine can reduce muscle pain during exercise; however, the efficacy of caffeine in improving muscle soreness and recovery from a demanding long-duration exercise bout has not been established. The purpose of this study was to investigate the effects of caffeine intake on ratings of perceived muscle soreness (RPMS) and perceived lower extremity functionality (LEF) following the completion of a 164-km endurance cycling event. Before and after cycling RPMS (1-to-6; 6 = severe soreness) and LEF (0-to-80; 80 = full functionality) were assessed by questionnaires. Subjects ingested 3 mg/kg body mass of caffeine or placebo pills in a randomized, double-blind fashion immediately after the ride and for the next 4 mornings (i.e., â¼800 hours) and 3 afternoons (i.e., â¼1200 hours). Before each ingestion, RPMS and LEF were assessed. Afternoon ratings of LEF were greater with caffeine ingestion the first day postride (65.0 Â± 6.1 vs. 72.3 Â± 6.7; for placebo and caffeine, respectively; p = 0.04), but at no other time points (p  0.05). The caffeine group tended to have lower overall RPMS in the afternoon versus placebo (i.e., main effect of group; 1.1 Â± 0.2 vs. 0.5 Â± 0.2; p = 0.09). Afternoon RPMS for the legs was significantly lower in the caffeine group (main effect of caffeine; 1.3 Â± 0.2 vs. 0.5 Â± 0.3; p = 0.05). In conclusion, ingesting caffeine improved RPMS for the legs, but not LEF in the days following an endurance cycling event. Athletes may benefit from ingesting caffeine in the days following an arduous exercise bout to relieve feelings of soreness and reduced functionality.","tags":null,"title":"Effect of Caffeine on Perceived Soreness and Functionality Following an Endurance Cycling Event","type":"publication"}]